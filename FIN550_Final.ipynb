{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc5e1ab",
   "metadata": {},
   "source": [
    "---\n",
    "# **Property Assessment CCAO:** FIN 550 Final Project\n",
    "\n",
    "This R script contains the full workflow to:\n",
    "   - Load and process (ETL) Cook County property datasets\n",
    "   - Perform Exploratory Data Analysis (EDA)\n",
    "   - Develop and apply models for predicting residential property values\n",
    " \n",
    "The script produces the final 'assessed_value.csv' file for project submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2022bdc8",
   "metadata": {},
   "source": [
    "---\n",
    "### **Extract, Transform, Load**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946ff27e",
   "metadata": {},
   "source": [
    "##### Install & Load Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "adcd69b8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required packages loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Install and load required packages\n",
    "\n",
    "# Function to install packages if not already installed\n",
    "install_if_missing <- function(package) {\n",
    "  if (!require(package, character.only = TRUE, quietly = TRUE)) {\n",
    "    install.packages(package, dependencies = TRUE)\n",
    "  }\n",
    "}\n",
    "\n",
    "# Data manipulation and ETL\n",
    "install_if_missing(\"readr\")\n",
    "install_if_missing(\"dplyr\")\n",
    "install_if_missing(\"tidyr\")\n",
    "install_if_missing(\"data.table\")\n",
    "\n",
    "# EDA and visualization\n",
    "install_if_missing(\"ggplot2\")\n",
    "install_if_missing(\"corrplot\")\n",
    "install_if_missing(\"GGally\")\n",
    "install_if_missing(\"skimr\")\n",
    "\n",
    "# Modeling - Linear Models\n",
    "install_if_missing(\"caret\")\n",
    "install_if_missing(\"glmnet\")\n",
    "\n",
    "# Modeling - Tree-based methods\n",
    "install_if_missing(\"rpart\")\n",
    "install_if_missing(\"rpart.plot\")\n",
    "install_if_missing(\"randomForest\")\n",
    "install_if_missing(\"xgboost\")\n",
    "\n",
    "# Model evaluation and tuning\n",
    "install_if_missing(\"Metrics\")\n",
    "install_if_missing(\"MLmetrics\")\n",
    "\n",
    "# Missing data imputation\n",
    "install_if_missing(\"mice\")\n",
    "\n",
    "# Load libraries\n",
    "library(readr)       # Reading CSV files\n",
    "library(dplyr)       # Data manipulation\n",
    "library(tidyr)       # Data tidying\n",
    "library(data.table)  # Fast data manipulation\n",
    "\n",
    "library(ggplot2)     # Visualization\n",
    "library(corrplot)    # Correlation plots\n",
    "library(GGally)      # Pairwise plots\n",
    "library(skimr)       # Summary statistics\n",
    "\n",
    "library(caret)       # Model training and evaluation\n",
    "library(glmnet)      # Regularized regression (Ridge, Lasso, Elastic Net)\n",
    "\n",
    "library(rpart)       # Decision trees\n",
    "library(rpart.plot)  # Decision tree visualization\n",
    "library(randomForest) # Random Forest\n",
    "library(xgboost)     # XGBoost\n",
    "\n",
    "library(Metrics)     # Model evaluation metrics\n",
    "library(MLmetrics)   # Additional ML metrics\n",
    "\n",
    "library(mice)        # Multiple imputation by chained equations\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set.seed(550)\n",
    "\n",
    "cat(\"All required packages loaded successfully.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b5de2",
   "metadata": {},
   "source": [
    "##### Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "12f3fef0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m50000\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m63\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (8): meta_cdu, meta_deed_type, geo_property_city, geo_property_zip, geo...\n",
      "\u001b[32mdbl\u001b[39m (52): sale_price, meta_class, meta_town_code, meta_nbhd, meta_certified_...\n",
      "\u001b[33mlgl\u001b[39m  (3): ind_large_home, ind_garage, ind_arms_length\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m10000\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m63\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (8): meta_cdu, meta_deed_type, geo_property_city, geo_property_zip, geo...\n",
      "\u001b[32mdbl\u001b[39m (52): pid, meta_class, meta_town_code, meta_nbhd, meta_certified_est_bld...\n",
      "\u001b[33mlgl\u001b[39m  (3): ind_large_home, ind_garage, ind_arms_length\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historic Data Shape: 50000 63 \n",
      "Predict Set Shape: 10000 63 \n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "historic_data <- read_csv('data/historic_property_data.csv')\n",
    "predict_set <- read_csv('data/predict_property_data.csv')\n",
    "\n",
    "# Display basic information about the datasets\n",
    "cat(\"Historic Data Shape:\", dim(historic_data), \"\\n\")\n",
    "cat(\"Predict Set Shape:\", dim(predict_set), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22ed310",
   "metadata": {},
   "source": [
    "##### Observe Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "05f1875b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Missing Values in Historic Data ===\n",
      "                    Variable Missing_Count Missing_Percent\n",
      "             char_renovation         49741           99.48\n",
      "                    meta_cdu         47172           94.34\n",
      "                   char_apts         43093           86.19\n",
      "                  char_porch         40725           81.45\n",
      "             char_attic_fnsh         33453           66.91\n",
      "                char_tp_dsgn         27173           54.35\n",
      "                char_tp_plan         14394           28.79\n",
      "              char_gar1_area          7090           14.18\n",
      "              char_gar1_cnst          7088           14.18\n",
      "               char_gar1_att          7088           14.18\n",
      "                    geo_fips          1103            2.21\n",
      "            geo_municipality          1103            2.21\n",
      "                  char_oheat           172            0.34\n",
      "               geo_tract_pop           162            0.32\n",
      "              geo_white_perc           162            0.32\n",
      "              geo_black_perc           162            0.32\n",
      "              geo_asian_perc           162            0.32\n",
      "                geo_his_perc           162            0.32\n",
      "              geo_other_perc           162            0.32\n",
      "             geo_ohare_noise           162            0.32\n",
      "              geo_floodplain           162            0.32\n",
      "         geo_fs_flood_factor           162            0.32\n",
      " geo_fs_flood_risk_direction           162            0.32\n",
      "             geo_withinmr100           162            0.32\n",
      "          geo_withinmr101300           162            0.32\n",
      "    geo_school_elem_district           162            0.32\n",
      "      geo_school_hs_district           162            0.32\n",
      "              econ_midincome           162            0.32\n",
      "           geo_property_city           131            0.26\n",
      "            geo_property_zip           131            0.26\n",
      "              char_cnst_qlty            57            0.11\n",
      "               char_ext_wall            26            0.05\n",
      "              char_roof_cnst            26            0.05\n",
      "                   char_heat            26            0.05\n",
      "             char_attic_type            26            0.05\n",
      "                   char_site            26            0.05\n",
      "             char_repair_cnd            26            0.05\n",
      "                   char_bsmt            25            0.05\n",
      "               char_bsmt_fin            25            0.05\n",
      "                   char_frpl            25            0.05\n",
      "              char_gar1_size            24            0.05\n",
      "                    char_use            24            0.05\n",
      "                  ind_garage            24            0.05\n",
      "                    char_air            23            0.05\n",
      "              char_type_resd            23            0.05\n",
      "\n",
      "Total columns with missing values: 45 \n",
      "\n",
      "=== Missing Values in Predict Set ===\n",
      "          Variable Missing_Count Missing_Percent\n",
      "   char_renovation          9951           99.51\n",
      "          meta_cdu          9418           94.18\n",
      "         char_apts          8778           87.78\n",
      "        char_porch          8245           82.45\n",
      "   char_attic_fnsh          6762           67.62\n",
      "      char_tp_dsgn          5112           51.12\n",
      "      char_tp_plan          2657           26.57\n",
      "    char_gar1_cnst          1383           13.83\n",
      "     char_gar1_att          1383           13.83\n",
      "    char_gar1_area          1383           13.83\n",
      "          geo_fips           213            2.13\n",
      "  geo_municipality           213            2.13\n",
      " geo_property_city            15            0.15\n",
      "  geo_property_zip            15            0.15\n",
      "    char_cnst_qlty            10            0.10\n",
      "        char_oheat             5            0.05\n",
      "     char_ext_wall             3            0.03\n",
      "    char_roof_cnst             3            0.03\n",
      "         char_bsmt             3            0.03\n",
      "     char_bsmt_fin             3            0.03\n",
      "         char_heat             3            0.03\n",
      "          char_air             3            0.03\n",
      "         char_frpl             3            0.03\n",
      "   char_attic_type             3            0.03\n",
      "         char_site             3            0.03\n",
      "    char_gar1_size             3            0.03\n",
      "   char_repair_cnd             3            0.03\n",
      "          char_use             3            0.03\n",
      "    char_type_resd             3            0.03\n",
      "        ind_garage             3            0.03\n",
      "\n",
      "Total columns with missing values: 30 \n",
      "\n",
      "=== Summary ===\n",
      "Historic Data - Total missing values: 282493 \n",
      "Predict Set - Total missing values: 55585 \n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in historic_data\n",
    "cat(\"\\n=== Missing Values in Historic Data ===\\n\")\n",
    "missing_historic <- colSums(is.na(historic_data))\n",
    "missing_historic_pct <- (missing_historic / nrow(historic_data)) * 100\n",
    "\n",
    "# Display columns with missing values\n",
    "missing_historic_df <- data.frame(\n",
    "  Variable = names(missing_historic),\n",
    "  Missing_Count = missing_historic,\n",
    "  Missing_Percent = round(missing_historic_pct, 2)\n",
    ") %>%\n",
    "  filter(Missing_Count > 0) %>%\n",
    "  arrange(desc(Missing_Count))\n",
    "\n",
    "if(nrow(missing_historic_df) > 0) {\n",
    "  print(missing_historic_df, row.names = FALSE)\n",
    "  cat(\"\\nTotal columns with missing values:\", nrow(missing_historic_df), \"\\n\")\n",
    "} else {\n",
    "  cat(\"No missing values found in historic data.\\n\")\n",
    "}\n",
    "\n",
    "# Check for missing values in predict_set\n",
    "cat(\"\\n=== Missing Values in Predict Set ===\\n\")\n",
    "missing_predict <- colSums(is.na(predict_set))\n",
    "missing_predict_pct <- (missing_predict / nrow(predict_set)) * 100\n",
    "\n",
    "# Display columns with missing values\n",
    "missing_predict_df <- data.frame(\n",
    "  Variable = names(missing_predict),\n",
    "  Missing_Count = missing_predict,\n",
    "  Missing_Percent = round(missing_predict_pct, 2)\n",
    ") %>%\n",
    "  filter(Missing_Count > 0) %>%\n",
    "  arrange(desc(Missing_Count))\n",
    "\n",
    "if(nrow(missing_predict_df) > 0) {\n",
    "  print(missing_predict_df, row.names = FALSE)\n",
    "  cat(\"\\nTotal columns with missing values:\", nrow(missing_predict_df), \"\\n\")\n",
    "} else {\n",
    "  cat(\"No missing values found in predict set.\\n\")\n",
    "}\n",
    "\n",
    "# Summary of missing values\n",
    "cat(\"\\n=== Summary ===\\n\")\n",
    "cat(\"Historic Data - Total missing values:\", sum(missing_historic), \"\\n\")\n",
    "cat(\"Predict Set - Total missing values:\", sum(missing_predict), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3f5903",
   "metadata": {},
   "source": [
    "##### Missing Values by Data Type *(Nominal, Ordinal, Integer, Continuous, Booleen)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e74ea94b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Missing Values by Data Type (Codebook-Informed) ===\n",
      "\n",
      "Historic Data:\n",
      "  Numeric    : 0.52% (1483 missing values)\n",
      "  Categorical: 99.24% (280338 missing values)\n",
      "  Boolean    : 0.24% (672 missing values)\n",
      "  Unknown    : 0.00% (0 missing values)\n",
      "  Total:       100.00% (282493 missing values)\n",
      "\n",
      "Predict Set:\n",
      "  Numeric    : 0.01% (3 missing values)\n",
      "  Categorical: 99.99% (55579 missing values)\n",
      "  Boolean    : 0.01% (3 missing values)\n",
      "  Unknown    : 0.00% (0 missing values)\n",
      "  Total:       100.00% (55585 missing values)\n"
     ]
    }
   ],
   "source": [
    "# Analyze missing values by codebook-based data type\n",
    "cat(\"\\n=== Missing Values by Data Type (Codebook-Informed) ===\\n\")\n",
    "\n",
    "# Load codebook if not already loaded\n",
    "if(!exists(\"codebook_df\")) {\n",
    "  codebook_df <- read.csv(\"data/codebook.csv\", stringsAsFactors = FALSE)\n",
    "}\n",
    "\n",
    "# Create a lookup table: name -> type (using codebook var_type and var_data_type for more granularity)\n",
    "get_codebook_types <- function() {\n",
    "  # Try to get a clean set of variable names mapping to their type and data type\n",
    "  out <- codebook_df\n",
    "  # All possible codebook variable names (columns in datasets) to possible types\n",
    "  # Favor var_name_standard (it's primary for standardization)\n",
    "  out <- out[!is.na(out$var_name_standard) & nzchar(out$var_name_standard), ]\n",
    "  var_type_map <- setNames(out$var_type, out$var_name_standard)\n",
    "  var_data_type_map <- setNames(out$var_data_type, out$var_name_standard)\n",
    "  return(list(type=var_type_map, datatype=var_data_type_map))\n",
    "}\n",
    "\n",
    "cb_types <- get_codebook_types()\n",
    "\n",
    "# Function to group codebook data types into our analysis buckets\n",
    "codebook_col_type <- function(var, cb_types) {\n",
    "  # var: column name\n",
    "  type1 <- cb_types$type[[var]]\n",
    "  type2 <- cb_types$datatype[[var]]\n",
    "  if (is.null(type1) && is.null(type2)) return(\"Unknown\")\n",
    "  \n",
    "  # Use var_type, then var_data_type to classify\n",
    "  # Explicit logic:\n",
    "  # - boolean: logical\n",
    "  # - categorical: categorical (nominal or ordinal handled together; deeper split possible using var_notes, but not here)\n",
    "  # - numeric: numeric (includes continuous, integer)\n",
    "  # - everything else: character/fallback\n",
    "  \n",
    "  # Map codebook types to user buckets:\n",
    "  # If it's explicit logical in codebook, call it 'Boolean'\n",
    "  if(!is.null(type2) && tolower(type2) == \"logical\") return(\"Boolean\")\n",
    "  if(!is.null(type1) && tolower(type1) == \"ind\") return(\"Boolean\")\n",
    "  \n",
    "  # Categorical can be nominal or ordinal: if type2 is \"categorical\" or type1 is \"char\"\n",
    "  if(!is.null(type2) && tolower(type2) == \"categorical\") return(\"Categorical\")\n",
    "  if(!is.null(type1) && type1 %in% c(\"char\", \"meta\", \"geo\", \"econ\")) {\n",
    "    # meta/geo/econ might include character or codes, but check var_data_type for \"categorical\"\n",
    "    if(!is.null(type2) && tolower(type2) == \"categorical\") return(\"Categorical\")\n",
    "  }\n",
    "  \n",
    "  # Numeric (continuous, integer)\n",
    "  if(!is.null(type2) && tolower(type2) == \"numeric\") return(\"Numeric\")\n",
    "  \n",
    "  # If anything says 'character'\n",
    "  if(!is.null(type2) && tolower(type2) == \"character\") return(\"Categorical\")\n",
    "  \n",
    "  # Fallback: Unknown\n",
    "  return(\"Unknown\")\n",
    "}\n",
    "\n",
    "# Calculate missing by codebook-based type\n",
    "analyze_missing_by_codebook_type <- function(data, dataset_name, cb_types) {\n",
    "  cat(\"\\n\", dataset_name, \":\\n\", sep = \"\")\n",
    "  cols_with_missing <- names(data)[colSums(is.na(data)) > 0]\n",
    "  if(length(cols_with_missing) == 0) {\n",
    "    cat(\"  No missing values found.\\n\")\n",
    "    return(NULL)\n",
    "  }\n",
    "  # Assign each col to codebook type\n",
    "  cb_type_per_col <- sapply(cols_with_missing, codebook_col_type, cb_types=cb_types)\n",
    "  types_for_summary <- c(\"Numeric\", \"Categorical\", \"Boolean\", \"Unknown\")\n",
    "  total_missing <- sum(is.na(data))\n",
    "  missing_vals_by_type <- sapply(types_for_summary, function(btype) {\n",
    "    these_cols <- cols_with_missing[cb_type_per_col == btype]\n",
    "    if(length(these_cols)>0) sum(is.na(data[these_cols])) else 0\n",
    "  })\n",
    "  # Calculate percentages\n",
    "  missing_pct_by_type <- if(total_missing>0) missing_vals_by_type/total_missing*100 else rep(0, length(missing_vals_by_type))\n",
    "  names(missing_vals_by_type) <- types_for_summary\n",
    "  names(missing_pct_by_type) <- types_for_summary\n",
    "  \n",
    "  # Print results\n",
    "  for(type_str in types_for_summary) {\n",
    "    cat(sprintf(\"  %-11s: %.2f%% (%d missing values)\\n\", \n",
    "                paste0(type_str, if(type_str==\"Boolean\") \"\" else \"\"),\n",
    "                round(missing_pct_by_type[type_str], 2),\n",
    "                missing_vals_by_type[type_str]))\n",
    "  }\n",
    "  cat(sprintf(\"  Total:       100.00%% (%d missing values)\\n\", total_missing))\n",
    "}\n",
    "\n",
    "# Apply to both datasets\n",
    "analyze_missing_by_codebook_type(historic_data, \"Historic Data\", cb_types)\n",
    "analyze_missing_by_codebook_type(predict_set, \"Predict Set\", cb_types)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20334962",
   "metadata": {},
   "source": [
    "##### Missing Value Handling *(Drop High-Missing Columns)*\n",
    "\n",
    "- Drop any column with >50% missing values from both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2a10ee0a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with >50% missing in historic data: 6 \n",
      "[1] \"meta_cdu\"        \"char_apts\"       \"char_tp_dsgn\"    \"char_attic_fnsh\"\n",
      "[5] \"char_renovation\" \"char_porch\"     \n",
      "\n",
      "Columns with >50% missing in predict set: 6 \n",
      "[1] \"meta_cdu\"        \"char_apts\"       \"char_tp_dsgn\"    \"char_attic_fnsh\"\n",
      "[5] \"char_renovation\" \"char_porch\"     \n",
      "\n",
      "Total unique columns to drop: 6 \n",
      "Dropped 6 columns from historic data\n",
      "Dropped 6 columns from predict set\n",
      "\n",
      "Remaining missing values in historic data: 41136 \n",
      "Remaining missing values in predict set: 7319 \n"
     ]
    }
   ],
   "source": [
    "# Identify columns with >50% missing in historic data\n",
    "high_missing_historic <- names(missing_historic_pct[missing_historic_pct > 50])\n",
    "cat(\"\\nColumns with >50% missing in historic data:\", length(high_missing_historic), \"\\n\")\n",
    "if(length(high_missing_historic) > 0) {\n",
    "  print(high_missing_historic)\n",
    "}\n",
    "\n",
    "# Identify columns with >50% missing in predict set\n",
    "high_missing_predict <- names(missing_predict_pct[missing_predict_pct > 50])\n",
    "cat(\"\\nColumns with >50% missing in predict set:\", length(high_missing_predict), \"\\n\")\n",
    "if(length(high_missing_predict) > 0) {\n",
    "  print(high_missing_predict)\n",
    "}\n",
    "\n",
    "# Get union of columns to drop (present in either dataset)\n",
    "cols_to_drop <- unique(c(high_missing_historic, high_missing_predict))\n",
    "cat(\"\\nTotal unique columns to drop:\", length(cols_to_drop), \"\\n\")\n",
    "\n",
    "# Drop high-missing columns from both datasets\n",
    "if(length(cols_to_drop) > 0) {\n",
    "  cols_to_drop_historic <- intersect(cols_to_drop, names(historic_data))\n",
    "  cols_to_drop_predict <- intersect(cols_to_drop, names(predict_set))\n",
    "  \n",
    "  if(length(cols_to_drop_historic) > 0) {\n",
    "    historic_data <- historic_data %>% select(-all_of(cols_to_drop_historic))\n",
    "    cat(\"Dropped\", length(cols_to_drop_historic), \"columns from historic data\\n\")\n",
    "  }\n",
    "  \n",
    "  if(length(cols_to_drop_predict) > 0) {\n",
    "    predict_set <- predict_set %>% select(-all_of(cols_to_drop_predict))\n",
    "    cat(\"Dropped\", length(cols_to_drop_predict), \"columns from predict set\\n\")\n",
    "  }\n",
    "}\n",
    "\n",
    "# Check remaining missing values\n",
    "remaining_missing_historic <- sum(is.na(historic_data))\n",
    "remaining_missing_predict <- sum(is.na(predict_set))\n",
    "\n",
    "cat(\"\\nRemaining missing values in historic data:\", remaining_missing_historic, \"\\n\")\n",
    "cat(\"Remaining missing values in predict set:\", remaining_missing_predict, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a801b20a",
   "metadata": {},
   "source": [
    "##### Missing Value Handling *(Analysis & Decision Support)*\n",
    "\n",
    "- Analyze missing data patterns to decide on imputation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "def77245",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for Historic Data \n",
      "\n",
      "--- Categorical Variable Distributions ---\n",
      "char_tp_plan(28.79% missing)\n",
      "char_gar1_cnst(14.18% missing)\n",
      "char_gar1_att(14.18% missing)\n",
      "char_gar1_area(14.18% missing)\n",
      "geo_fips(2.21% missing)\n",
      "geo_municipality(2.21% missing)\n",
      "char_oheat(0.34% missing)\n",
      "geo_school_elem_district(0.32% missing)\n",
      "geo_school_hs_district(0.32% missing)\n",
      "geo_property_city(0.26% missing)\n",
      "geo_property_zip(0.26% missing)\n",
      "char_cnst_qlty(0.11% missing)\n",
      "char_ext_wall(0.05% missing)\n",
      "char_roof_cnst(0.05% missing)\n",
      "char_bsmt(0.05% missing)\n",
      "char_bsmt_fin(0.05% missing)\n",
      "char_heat(0.05% missing)\n",
      "char_air(0.05% missing)\n",
      "char_attic_type(0.05% missing)\n",
      "char_site(0.05% missing)\n",
      "char_gar1_size(0.05% missing)\n",
      "char_repair_cnd(0.05% missing)\n",
      "char_use(0.05% missing)\n",
      "char_type_resd(0.05% missing)\n",
      "\n",
      "--- Numeric Variable Distributions ---\n",
      "geo_tract_pop(0.32% missing)\n",
      "geo_white_perc(0.32% missing)\n",
      "geo_black_perc(0.32% missing)\n",
      "geo_asian_perc(0.32% missing)\n",
      "geo_his_perc(0.32% missing)\n",
      "geo_other_perc(0.32% missing)\n",
      "geo_fs_flood_factor(0.32% missing)\n",
      "geo_fs_flood_risk_direction(0.32% missing)\n",
      "econ_midincome(0.32% missing)\n",
      "char_frpl(0.05% missing)\n",
      "\n",
      "--- Boolean Variable Distributions ---\n",
      "geo_ohare_noise(0.32% missing)\n",
      "geo_floodplain(0.32% missing)\n",
      "geo_withinmr100(0.32% missing)\n",
      "geo_withinmr101300(0.32% missing)\n",
      "ind_garage(0.05% missing)\n",
      "\n",
      "--- Unknown Variable Distributions ---\n",
      "No unknown variables with missing values.\n",
      "\n",
      "Analysis for Predict Set \n",
      "\n",
      "--- Categorical Variable Distributions ---\n",
      "char_tp_plan(26.57% missing)\n",
      "char_gar1_cnst(13.83% missing)\n",
      "char_gar1_att(13.83% missing)\n",
      "char_gar1_area(13.83% missing)\n",
      "geo_fips(2.13% missing)\n",
      "geo_municipality(2.13% missing)\n",
      "geo_property_city(0.15% missing)\n",
      "geo_property_zip(0.15% missing)\n",
      "char_cnst_qlty(0.1% missing)\n",
      "char_oheat(0.05% missing)\n",
      "char_ext_wall(0.03% missing)\n",
      "char_roof_cnst(0.03% missing)\n",
      "char_bsmt(0.03% missing)\n",
      "char_bsmt_fin(0.03% missing)\n",
      "char_heat(0.03% missing)\n",
      "char_air(0.03% missing)\n",
      "char_attic_type(0.03% missing)\n",
      "char_site(0.03% missing)\n",
      "char_gar1_size(0.03% missing)\n",
      "char_repair_cnd(0.03% missing)\n",
      "char_use(0.03% missing)\n",
      "char_type_resd(0.03% missing)\n",
      "\n",
      "--- Numeric Variable Distributions ---\n",
      "char_frpl(0.03% missing)\n",
      "\n",
      "--- Boolean Variable Distributions ---\n",
      "ind_garage(0.03% missing)\n",
      "\n",
      "--- Unknown Variable Distributions ---\n",
      "No unknown variables with missing values.\n",
      "\n",
      "=== Row-wise Missing Value Analysis ===\n",
      "\n",
      "--- Row completeness for Historic Data ---\n",
      "Rows with 0 missing values: 29704 (59.41%) \n",
      "Rows with 1-2 missing values: 12852 (25.70%) \n",
      "Rows with 3-5 missing values: 7240 (14.48%) \n",
      "Rows with >5 missing values: 204 (0.41%) \n",
      "\n",
      "Rows with missing categorical values: 20296 (40.59% of dataset)\n",
      "Data remaining if these rows dropped: 29704 (59.41% retention)\n",
      "\n",
      "--- Row completeness for Predict Set ---\n",
      "Rows with 0 missing values: 6160 (61.60%) \n",
      "Rows with 1-2 missing values: 2411 (24.11%) \n",
      "Rows with 3-5 missing values: 1424 (14.24%) \n",
      "Rows with >5 missing values: 5 (0.05%) \n",
      "\n",
      "Rows with missing categorical values: 3840 (38.40% of dataset)\n",
      "Data remaining if these rows dropped: 6160 (61.60% retention)\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze missing values by type, using CODEBOOK LOGIC (not R's class())\n",
    "analyze_missing_by_codebook_type_detailed <- function(data, dataset_name, cb_types) {\n",
    "  cat(\"Analysis for\", dataset_name, \"\\n\")\n",
    "  \n",
    "  # Find columns with missing values\n",
    "  cols_with_missing <- names(data)[colSums(is.na(data)) > 0]\n",
    "  \n",
    "  if(length(cols_with_missing) == 0) {\n",
    "    cat(\"No missing values found.\\n\")\n",
    "    return(NULL)\n",
    "  }\n",
    "  \n",
    "  # Assign codebook-based type to each column with missing values\n",
    "  cb_types_col <- sapply(\n",
    "    cols_with_missing, \n",
    "    function(var) codebook_col_type(var, cb_types), \n",
    "    USE.NAMES = FALSE\n",
    "  )\n",
    "  \n",
    "  # Create detailed analysis dataframe\n",
    "  missing_analysis <- data.frame(\n",
    "    Variable = cols_with_missing,\n",
    "    Codebook_Type = cb_types_col,\n",
    "    Missing_Count = colSums(is.na(data[cols_with_missing])),\n",
    "    Total_Rows = nrow(data),\n",
    "    stringsAsFactors = FALSE\n",
    "  ) %>%\n",
    "    mutate(\n",
    "      Missing_Percent = round((Missing_Count / Total_Rows) * 100, 2),\n",
    "      Data_Category = factor(Codebook_Type, \n",
    "                             levels = c(\"Numeric\", \"Categorical\", \"Boolean\", \"Unknown\"))\n",
    "    ) %>%\n",
    "    arrange(desc(Missing_Percent))\n",
    "  \n",
    "  # Analyze distributions for each codebook-based type\n",
    "  for(type_lbl in c(\"Categorical\", \"Numeric\", \"Boolean\", \"Unknown\")) {\n",
    "    n_vars <- sum(missing_analysis$Data_Category == type_lbl)\n",
    "    cat(sprintf(\"\\n--- %s Variable Distributions ---\\n\", type_lbl))\n",
    "    these_vars <- missing_analysis %>% filter(Data_Category == type_lbl) %>% pull(Variable)\n",
    "    if(length(these_vars) > 0) {\n",
    "      for(var in these_vars) {\n",
    "        cat(var, \"(\", missing_analysis$Missing_Percent[missing_analysis$Variable == var], \"% missing)\\n\", sep=\"\")\n",
    "      }\n",
    "    } else {\n",
    "      cat(sprintf(\"No %s variables with missing values.\\n\", tolower(type_lbl)))\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(missing_analysis)\n",
    "}\n",
    "\n",
    "# Analyze both datasets using codebook-derived types\n",
    "missing_analysis_historic <- analyze_missing_by_codebook_type_detailed(historic_data, \"Historic Data\", cb_types)\n",
    "cat(\"\\n\")\n",
    "missing_analysis_predict <- analyze_missing_by_codebook_type_detailed(predict_set, \"Predict Set\", cb_types)\n",
    "\n",
    "# Row-wise missing analysis (using codebook logic for consistent col selection)\n",
    "cat(\"\\n=== Row-wise Missing Value Analysis ===\\n\")\n",
    "\n",
    "analyze_row_completeness_cb <- function(data, dataset_name, missing_analysis_ref = NULL, type_target = \"Categorical\") {\n",
    "  cat(\"\\n--- Row completeness for\", dataset_name, \"---\\n\")\n",
    "  \n",
    "  # Count missing values per row\n",
    "  missing_per_row <- rowSums(is.na(data))\n",
    "  \n",
    "  cat(\"Rows with 0 missing values:\", sum(missing_per_row == 0), \n",
    "      sprintf(\"(%.2f%%)\", sum(missing_per_row == 0) / nrow(data) * 100), \"\\n\")\n",
    "  cat(\"Rows with 1-2 missing values:\", sum(missing_per_row >= 1 & missing_per_row <= 2), \n",
    "      sprintf(\"(%.2f%%)\", sum(missing_per_row >= 1 & missing_per_row <= 2) / nrow(data) * 100), \"\\n\")\n",
    "  cat(\"Rows with 3-5 missing values:\", sum(missing_per_row >= 3 & missing_per_row <= 5), \n",
    "      sprintf(\"(%.2f%%)\", sum(missing_per_row >= 3 & missing_per_row <= 5) / nrow(data) * 100), \"\\n\")\n",
    "  cat(\"Rows with >5 missing values:\", sum(missing_per_row > 5), \n",
    "      sprintf(\"(%.2f%%)\", sum(missing_per_row > 5) / nrow(data) * 100), \"\\n\")\n",
    "  \n",
    "  # If we have type-targeted analysis (e.g. \"Categorical\", \"Boolean\"), show effect of dropping those rows\n",
    "  if(!is.null(missing_analysis_ref)) {\n",
    "    type_cols <- missing_analysis_ref %>% \n",
    "      filter(Data_Category == type_target) %>% \n",
    "      pull(Variable)\n",
    "    type_cols <- intersect(type_cols, names(data))\n",
    "    \n",
    "    if(length(type_cols) > 0) {\n",
    "      rows_with_type_missing <- rowSums(is.na(data[type_cols])) > 0\n",
    "      cat(sprintf(\"\\nRows with missing %s values: %d (%.2f%% of dataset)\\n\",\n",
    "                  tolower(type_target), sum(rows_with_type_missing), \n",
    "                  sum(rows_with_type_missing) / nrow(data) * 100))\n",
    "      cat(sprintf(\"Data remaining if these rows dropped: %d (%.2f%% retention)\\n\",\n",
    "                  nrow(data) - sum(rows_with_type_missing),\n",
    "                  (nrow(data) - sum(rows_with_type_missing)) / nrow(data) * 100))\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(missing_per_row)\n",
    "}\n",
    "\n",
    "row_missing_historic <- analyze_row_completeness_cb(historic_data, \"Historic Data\", missing_analysis_historic, \"Categorical\")\n",
    "row_missing_predict <- analyze_row_completeness_cb(predict_set, \"Predict Set\", missing_analysis_predict, \"Categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61416024",
   "metadata": {},
   "source": [
    "##### Missing Value Handling *(MICE Protocol)*\n",
    "\n",
    "- **MICE Imputation** — Apply multivariate imputation by chained equations to remaining missing values:\n",
    "\n",
    "   - ***PMM*** *(Predictive Mean Matching)* *{Numeric variables}*: Predicts missing values by matching to observed values with similar predicted means, preserving the original distribution\n",
    "   - ***CART*** *(Classification and Regression Trees)* *{Categorical Variables}*: Uses decision tree models to predict missing categories based on other variables\n",
    "   - ***LogReg*** *(Logistic Regression)* *{Logical/Binary Variables}*: Models the probability of TRUE/FALSE outcomes using logistic regression\n",
    "\n",
    " - MICE preserves relationships between variables and maintains distributional properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4cb845c2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Converting Categorical Variables to Factors ===\n",
      "  Converted historic_data$meta_class to factor (14 levels)\n",
      "  Converted historic_data$meta_town_code to factor (38 levels)\n",
      "  Converted historic_data$meta_nbhd to factor (845 levels)\n",
      "  Converted historic_data$meta_deed_type to factor (3 levels)\n",
      "  Converted historic_data$char_ext_wall to factor (4 levels)\n",
      "  Converted historic_data$char_roof_cnst to factor (6 levels)\n",
      "  Converted historic_data$char_bsmt to factor (4 levels)\n",
      "  Converted historic_data$char_bsmt_fin to factor (3 levels)\n",
      "  Converted historic_data$char_heat to factor (4 levels)\n",
      "  Converted historic_data$char_oheat to factor (2 levels)\n",
      "  Converted historic_data$char_air to factor (2 levels)\n",
      "  Converted historic_data$char_attic_type to factor (3 levels)\n",
      "  Converted historic_data$char_tp_plan to factor (2 levels)\n",
      "  Converted historic_data$char_cnst_qlty to factor (2 levels)\n",
      "  Converted historic_data$char_site to factor (3 levels)\n",
      "  Converted historic_data$char_gar1_size to factor (8 levels)\n",
      "  Converted historic_data$char_gar1_cnst to factor (4 levels)\n",
      "  Converted historic_data$char_gar1_att to factor (2 levels)\n",
      "  Converted historic_data$char_gar1_area to factor (2 levels)\n",
      "  Converted historic_data$char_repair_cnd to factor (3 levels)\n",
      "  Converted historic_data$char_use to factor (2 levels)\n",
      "  Converted historic_data$char_type_resd to factor (9 levels)\n",
      "  Converted historic_data$geo_property_city to factor (132 levels)\n",
      "  Converted historic_data$geo_property_zip to factor (169 levels)\n",
      "  Converted historic_data$geo_fips to factor (126 levels)\n",
      "  Converted historic_data$geo_municipality to factor (126 levels)\n",
      "  Converted historic_data$geo_ohare_noise to logical\n",
      "  Converted historic_data$geo_floodplain to logical\n",
      "  Converted historic_data$geo_withinmr100 to logical\n",
      "  Converted historic_data$geo_withinmr101300 to logical\n",
      "  Converted historic_data$geo_school_elem_district to factor (475 levels)\n",
      "  Converted historic_data$geo_school_hs_district to factor (79 levels)\n",
      "  Converted predict_set$meta_class to factor (14 levels)\n",
      "  Converted predict_set$meta_town_code to factor (38 levels)\n",
      "  Converted predict_set$meta_nbhd to factor (803 levels)\n",
      "  Converted predict_set$meta_deed_type to factor (3 levels)\n",
      "  Converted predict_set$char_ext_wall to factor (4 levels)\n",
      "  Converted predict_set$char_roof_cnst to factor (6 levels)\n",
      "  Converted predict_set$char_bsmt to factor (4 levels)\n",
      "  Converted predict_set$char_bsmt_fin to factor (3 levels)\n",
      "  Converted predict_set$char_heat to factor (4 levels)\n",
      "  Converted predict_set$char_oheat to factor (2 levels)\n",
      "  Converted predict_set$char_air to factor (2 levels)\n",
      "  Converted predict_set$char_attic_type to factor (3 levels)\n",
      "  Converted predict_set$char_tp_plan to factor (2 levels)\n",
      "  Converted predict_set$char_cnst_qlty to factor (2 levels)\n",
      "  Converted predict_set$char_site to factor (3 levels)\n",
      "  Converted predict_set$char_gar1_size to factor (8 levels)\n",
      "  Converted predict_set$char_gar1_cnst to factor (4 levels)\n",
      "  Converted predict_set$char_gar1_att to factor (2 levels)\n",
      "  Converted predict_set$char_gar1_area to factor (2 levels)\n",
      "  Converted predict_set$char_repair_cnd to factor (3 levels)\n",
      "  Converted predict_set$char_use to factor (2 levels)\n",
      "  Converted predict_set$char_type_resd to factor (9 levels)\n",
      "  Converted predict_set$geo_property_city to factor (130 levels)\n",
      "  Converted predict_set$geo_property_zip to factor (166 levels)\n",
      "  Converted predict_set$geo_fips to factor (125 levels)\n",
      "  Converted predict_set$geo_municipality to factor (125 levels)\n",
      "  Converted predict_set$geo_ohare_noise to logical\n",
      "  Converted predict_set$geo_floodplain to logical\n",
      "  Converted predict_set$geo_withinmr100 to logical\n",
      "  Converted predict_set$geo_withinmr101300 to logical\n",
      "  Converted predict_set$geo_school_elem_district to factor (465 levels)\n",
      "  Converted predict_set$geo_school_hs_district to factor (79 levels)\n",
      "Categorical conversion complete.\n",
      "Timestamp: 2025-11-25 17:13:18.422846\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# PRE-IMPUTATION: CONVERT CATEGORICALS TO FACTORS\n",
    "# =====================================================\n",
    "\n",
    "cat(\"\\n=== Converting Categorical Variables to Factors ===\\n\")\n",
    "flush.console()\n",
    "\n",
    "# Get codebook types\n",
    "cb_types <- get_codebook_types()\n",
    "\n",
    "# Convert categorical columns in historic_data\n",
    "for(col in names(historic_data)) {\n",
    "  # Skip if column doesn't exist in codebook\n",
    "  if(!col %in% names(cb_types$type)) {\n",
    "    next\n",
    "  }\n",
    "  \n",
    "  col_type <- codebook_col_type(col, cb_types)\n",
    "  \n",
    "  if(col_type == \"Categorical\" && !is.factor(historic_data[[col]])) {\n",
    "    historic_data[[col]] <- as.factor(historic_data[[col]])\n",
    "    cat(\"  Converted historic_data$\", col, \" to factor (\", \n",
    "        length(levels(historic_data[[col]])), \" levels)\\n\", sep = \"\")\n",
    "  } else if(col_type == \"Boolean\" && !is.logical(historic_data[[col]])) {\n",
    "    historic_data[[col]] <- as.logical(historic_data[[col]])\n",
    "    cat(\"  Converted historic_data$\", col, \" to logical\\n\", sep = \"\")\n",
    "  }\n",
    "}\n",
    "\n",
    "# Convert categorical columns in predict_set\n",
    "for(col in names(predict_set)) {\n",
    "  # Skip if column doesn't exist in codebook\n",
    "  if(!col %in% names(cb_types$type)) {\n",
    "    next\n",
    "  }\n",
    "  \n",
    "  col_type <- codebook_col_type(col, cb_types)\n",
    "  \n",
    "  if(col_type == \"Categorical\" && !is.factor(predict_set[[col]])) {\n",
    "    predict_set[[col]] <- as.factor(predict_set[[col]])\n",
    "    cat(\"  Converted predict_set$\", col, \" to factor (\", \n",
    "        length(levels(predict_set[[col]])), \" levels)\\n\", sep = \"\")\n",
    "  } else if(col_type == \"Boolean\" && !is.logical(predict_set[[col]])) {\n",
    "    predict_set[[col]] <- as.logical(predict_set[[col]])\n",
    "    cat(\"  Converted predict_set$\", col, \" to logical\\n\", sep = \"\")\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"Categorical conversion complete.\\n\")\n",
    "cat(sprintf(\"Timestamp: %s\\n\", Sys.time()))\n",
    "flush.console()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee9eafb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CHECKPOINT] About to check if imputation needed...\n",
      "\n",
      "=== Imputing Missing Values with MICE ===\n",
      "Timestamp: 2025-11-25 17:13:18.459939\n",
      "\n",
      "--- Processing Historic Data ---\n",
      "Timestamp: 2025-11-25 17:13:18.46046\n",
      "[PROGRESS] Found 39 columns with missing values\n",
      "[PROGRESS] Numeric: 10, Categorical: 24, Boolean: 5\n",
      "Variables with missing values: 39 \n",
      "\n",
      "=== Imputation Complexity Analysis (Historic Data) ===\n",
      "char_ext_wall: 26 missing, 4 unique values, type=factor\n",
      "char_roof_cnst: 26 missing, 6 unique values, type=factor\n",
      "char_bsmt: 25 missing, 4 unique values, type=factor\n",
      "char_bsmt_fin: 25 missing, 3 unique values, type=factor\n",
      "char_heat: 26 missing, 4 unique values, type=factor\n",
      "char_oheat: 172 missing, 2 unique values, type=factor\n",
      "char_air: 23 missing, 2 unique values, type=factor\n",
      "char_frpl: 25 missing, 10 unique values, type=numeric\n",
      "char_attic_type: 26 missing, 3 unique values, type=factor\n",
      "char_tp_plan: 14394 missing, 2 unique values, type=factor\n",
      "char_cnst_qlty: 57 missing, 2 unique values, type=factor\n",
      "char_site: 26 missing, 3 unique values, type=factor\n",
      "char_gar1_size: 24 missing, 8 unique values, type=factor\n",
      "char_gar1_cnst: 7088 missing, 4 unique values, type=factor\n",
      "char_gar1_att: 7088 missing, 2 unique values, type=factor\n",
      "char_gar1_area: 7090 missing, 2 unique values, type=factor\n",
      "char_repair_cnd: 26 missing, 3 unique values, type=factor\n",
      "char_use: 24 missing, 2 unique values, type=factor\n",
      "char_type_resd: 23 missing, 9 unique values, type=factor\n",
      "geo_property_city: 131 missing, 132 unique values, type=factor\n",
      "geo_property_zip: 131 missing, 169 unique values, type=factor\n",
      "geo_tract_pop: 162 missing, 1160 unique values, type=numeric\n",
      "geo_white_perc: 162 missing, 1243 unique values, type=numeric\n",
      "geo_black_perc: 162 missing, 1232 unique values, type=numeric\n",
      "geo_asian_perc: 162 missing, 1012 unique values, type=numeric\n",
      "geo_his_perc: 162 missing, 1238 unique values, type=numeric\n",
      "geo_other_perc: 162 missing, 1100 unique values, type=numeric\n",
      "geo_fips: 1103 missing, 126 unique values, type=factor\n",
      "geo_municipality: 1103 missing, 126 unique values, type=factor\n",
      "geo_ohare_noise: 162 missing, 2 unique values, type=logical\n",
      "geo_floodplain: 162 missing, 2 unique values, type=logical\n",
      "geo_fs_flood_factor: 162 missing, 10 unique values, type=numeric\n",
      "geo_fs_flood_risk_direction: 162 missing, 3 unique values, type=numeric\n",
      "geo_withinmr100: 162 missing, 2 unique values, type=logical\n",
      "geo_withinmr101300: 162 missing, 2 unique values, type=logical\n",
      "geo_school_elem_district: 162 missing, 475 unique values, type=factor\n",
      "geo_school_hs_district: 162 missing, 79 unique values, type=factor\n",
      "econ_midincome: 162 missing, 1247 unique values, type=numeric\n",
      "ind_garage: 24 missing, 2 unique values, type=logical\n",
      "\n",
      "[PROGRESS] Creating predictor matrix with quickpred()...\n",
      "Timestamp: 2025-11-25 17:13:18.516698\n",
      "[PROGRESS] Predictor matrix created successfully\n",
      "Timestamp: 2025-11-25 17:13:18.998738\n",
      "\n",
      "=== Assigning Imputation Methods (Historic Data) ===\n",
      "  char_ext_wall: cart (4 categories)\n",
      "  char_roof_cnst: cart (6 categories)\n",
      "  char_bsmt: cart (4 categories)\n",
      "  char_bsmt_fin: cart (3 categories)\n",
      "  char_heat: cart (4 categories)\n",
      "  char_oheat: cart (2 categories)\n",
      "  char_air: cart (2 categories)\n",
      "  char_frpl: pmm (numeric)\n",
      "  char_attic_type: cart (3 categories)\n",
      "  char_tp_plan: cart (2 categories)\n",
      "  char_cnst_qlty: cart (2 categories)\n",
      "  char_site: cart (3 categories)\n",
      "  char_gar1_size: cart (8 categories)\n",
      "  char_gar1_cnst: cart (4 categories)\n",
      "  char_gar1_att: cart (2 categories)\n",
      "  char_gar1_area: cart (2 categories)\n",
      "  char_repair_cnd: cart (3 categories)\n",
      "  char_use: cart (2 categories)\n",
      "  char_type_resd: cart (9 categories)\n",
      "  geo_property_city: sample (132 categories - too many for polyreg)\n",
      "  geo_property_zip: sample (169 categories - too many for polyreg)\n",
      "  geo_tract_pop: pmm (numeric)\n",
      "  geo_white_perc: pmm (numeric)\n",
      "  geo_black_perc: pmm (numeric)\n",
      "  geo_asian_perc: pmm (numeric)\n",
      "  geo_his_perc: pmm (numeric)\n",
      "  geo_other_perc: pmm (numeric)\n",
      "  geo_fips: sample (126 categories - too many for polyreg)\n",
      "  geo_municipality: sample (126 categories - too many for polyreg)\n",
      "  geo_ohare_noise: logreg (boolean)\n",
      "  geo_floodplain: logreg (boolean)\n",
      "  geo_fs_flood_factor: pmm (numeric)\n",
      "  geo_fs_flood_risk_direction: pmm (numeric)\n",
      "  geo_withinmr100: logreg (boolean)\n",
      "  geo_withinmr101300: logreg (boolean)\n",
      "  geo_school_elem_district: sample (475 categories - too many for polyreg)\n",
      "  geo_school_hs_district: sample (79 categories - too many for polyreg)\n",
      "  econ_midincome: pmm (numeric)\n",
      "  ind_garage: logreg (boolean)\n",
      "\n",
      "[METHOD SUMMARY]\n",
      "  PMM: 10 variables\n",
      "  CART: 18 variables\n",
      "  PolyReg: 0 variables\n",
      "  Sample: 6 variables\n",
      "  LogReg: 5 variables\n",
      "\n",
      "[PROGRESS] Starting MICE imputation on historic data...\n",
      "Timestamp: 2025-11-25 17:13:19.084279 - This may take several minutes\n",
      "Note: Progress will update after each iteration completes\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# MICE IMPUTATION\n",
    "# =====================================================\n",
    "\n",
    "cat(\"\\n[CHECKPOINT] About to check if imputation needed...\\n\")\n",
    "flush.console()\n",
    "\n",
    "# Impute remaining missing values using MICE if any remain\n",
    "if(remaining_missing_historic > 0 || remaining_missing_predict > 0) {\n",
    "  cat(\"\\n=== Imputing Missing Values with MICE ===\\n\")\n",
    "  cat(sprintf(\"Timestamp: %s\\n\", Sys.time()))\n",
    "  flush.console()\n",
    "\n",
    "  set.seed(550)\n",
    "\n",
    "  # Impute historic data\n",
    "  if(remaining_missing_historic > 0) {\n",
    "    cat(\"\\n--- Processing Historic Data ---\\n\")\n",
    "    cat(sprintf(\"Timestamp: %s\\n\", Sys.time()))\n",
    "    flush.console()\n",
    "    \n",
    "    cols_with_missing_historic <- names(historic_data)[colSums(is.na(historic_data)) > 0]\n",
    "    \n",
    "    cat(sprintf(\"[PROGRESS] Found %d columns with missing values\\n\", length(cols_with_missing_historic)))\n",
    "    flush.console()\n",
    "    \n",
    "    # Identify numeric columns with missing values for statistics tracking\n",
    "    numeric_missing_historic <- cols_with_missing_historic[\n",
    "      sapply(cols_with_missing_historic, function(col) {\n",
    "        col %in% names(cb_types$type) && codebook_col_type(col, cb_types) == \"Numeric\"\n",
    "      })\n",
    "    ]\n",
    "    \n",
    "    # Identify categorical columns with missing values for distribution tracking\n",
    "    categorical_missing_historic <- cols_with_missing_historic[\n",
    "      sapply(cols_with_missing_historic, function(col) {\n",
    "        col %in% names(cb_types$type) && codebook_col_type(col, cb_types) == \"Categorical\"\n",
    "      })\n",
    "    ]\n",
    "    \n",
    "    # Identify boolean columns with missing values for distribution tracking\n",
    "    boolean_missing_historic <- cols_with_missing_historic[\n",
    "      sapply(cols_with_missing_historic, function(col) {\n",
    "        col %in% names(cb_types$type) && codebook_col_type(col, cb_types) == \"Boolean\"\n",
    "      })\n",
    "    ]\n",
    "\n",
    "    cat(sprintf(\"[PROGRESS] Numeric: %d, Categorical: %d, Boolean: %d\\n\", \n",
    "                length(numeric_missing_historic), \n",
    "                length(categorical_missing_historic),\n",
    "                length(boolean_missing_historic)))\n",
    "    flush.console()\n",
    "\n",
    "    if(length(numeric_missing_historic) > 0) {\n",
    "      original_stats_historic <- data.frame(\n",
    "        Variable = numeric_missing_historic,\n",
    "        Original_Mean = sapply(historic_data[numeric_missing_historic], mean, na.rm = TRUE),\n",
    "        Original_Median = sapply(historic_data[numeric_missing_historic], median, na.rm = TRUE),\n",
    "        Original_Variance = sapply(historic_data[numeric_missing_historic], var, na.rm = TRUE),\n",
    "        stringsAsFactors = FALSE\n",
    "      )\n",
    "    }\n",
    "    \n",
    "    # Store original categorical distributions\n",
    "    if(length(categorical_missing_historic) > 0) {\n",
    "      original_cat_dist_historic <- list()\n",
    "      for(col in categorical_missing_historic) {\n",
    "        original_cat_dist_historic[[col]] <- prop.table(table(historic_data[[col]], useNA = \"no\"))\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    # Store original boolean distributions\n",
    "    if(length(boolean_missing_historic) > 0) {\n",
    "      original_bool_dist_historic <- list()\n",
    "      for(col in boolean_missing_historic) {\n",
    "        original_bool_dist_historic[[col]] <- prop.table(table(historic_data[[col]], useNA = \"no\"))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    cat(\"Variables with missing values:\", length(cols_with_missing_historic), \"\\n\")\n",
    "    \n",
    "    # Diagnostic: Analyze imputation complexity\n",
    "    cat(\"\\n=== Imputation Complexity Analysis (Historic Data) ===\\n\")\n",
    "    for(col in cols_with_missing_historic) {\n",
    "      n_missing <- sum(is.na(historic_data[[col]]))\n",
    "      n_unique <- length(unique(historic_data[[col]][!is.na(historic_data[[col]])]))\n",
    "      col_type <- class(historic_data[[col]])[1]\n",
    "      \n",
    "      cat(sprintf(\"%s: %d missing, %d unique values, type=%s\\n\",\n",
    "                  col, n_missing, n_unique, col_type))\n",
    "    }\n",
    "    flush.console()\n",
    "    \n",
    "    cat(\"\\n[PROGRESS] Creating predictor matrix with quickpred()...\\n\")\n",
    "    cat(sprintf(\"Timestamp: %s\\n\", Sys.time()))\n",
    "    flush.console()\n",
    "    \n",
    "    pred_matrix_historic <- quickpred(historic_data, mincor = 0.3, minpuc = 0.5)\n",
    "    \n",
    "    cat(\"[PROGRESS] Predictor matrix created successfully\\n\")\n",
    "    cat(sprintf(\"Timestamp: %s\\n\", Sys.time()))\n",
    "    flush.console()\n",
    "    \n",
    "    impute_methods_historic <- make.method(historic_data)\n",
    "\n",
    "    # Assign imputation methods based on codebook data types\n",
    "    cat(\"\\n=== Assigning Imputation Methods (Historic Data) ===\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    method_counts <- list(pmm = 0, cart = 0, polyreg = 0, sample = 0, logreg = 0)\n",
    "    \n",
    "    for(col in names(historic_data)) {\n",
    "      if(sum(is.na(historic_data[[col]])) > 0) {\n",
    "        # Skip if column doesn't exist in codebook\n",
    "        if(!col %in% names(cb_types$type)) {\n",
    "          cat(sprintf(\"  %s: skipped (not in codebook)\\n\", col))\n",
    "          next\n",
    "        }\n",
    "        \n",
    "        col_type <- codebook_col_type(col, cb_types)\n",
    "        n_unique <- length(unique(historic_data[[col]][!is.na(historic_data[[col]])]))\n",
    "        \n",
    "        if(col_type == \"Numeric\") {\n",
    "          impute_methods_historic[col] <- \"pmm\"\n",
    "          method_counts$pmm <- method_counts$pmm + 1\n",
    "          cat(sprintf(\"  %s: pmm (numeric)\\n\", col))\n",
    "          \n",
    "        } else if(col_type == \"Categorical\") {\n",
    "          # Ensure it's a factor\n",
    "          if(!is.factor(historic_data[[col]])) {\n",
    "            historic_data[[col]] <- as.factor(historic_data[[col]])\n",
    "          }\n",
    "          \n",
    "          # Handle based on cardinality\n",
    "          if(n_unique <= 10) {\n",
    "            impute_methods_historic[col] <- \"cart\"\n",
    "            method_counts$cart <- method_counts$cart + 1\n",
    "            cat(sprintf(\"  %s: cart (%d categories)\\n\", col, n_unique))\n",
    "          } else if(n_unique <= 50) {\n",
    "            impute_methods_historic[col] <- \"polyreg\"\n",
    "            method_counts$polyreg <- method_counts$polyreg + 1\n",
    "            cat(sprintf(\"  %s: polyreg (%d categories)\\n\", col, n_unique))\n",
    "          } else {\n",
    "            impute_methods_historic[col] <- \"sample\"\n",
    "            method_counts$sample <- method_counts$sample + 1\n",
    "            cat(sprintf(\"  %s: sample (%d categories - too many for polyreg)\\n\", col, n_unique))\n",
    "          }\n",
    "          \n",
    "        } else if(col_type == \"Boolean\") {\n",
    "          # Ensure it's a factor for logreg\n",
    "          if(!is.factor(historic_data[[col]])) {\n",
    "            historic_data[[col]] <- as.factor(historic_data[[col]])\n",
    "          }\n",
    "          impute_methods_historic[col] <- \"logreg\"\n",
    "          method_counts$logreg <- method_counts$logreg + 1\n",
    "          cat(sprintf(\"  %s: logreg (boolean)\\n\", col))\n",
    "          \n",
    "        } else {\n",
    "          # Fallback for unknown types\n",
    "          if(is.numeric(historic_data[[col]])) {\n",
    "            impute_methods_historic[col] <- \"pmm\"\n",
    "            method_counts$pmm <- method_counts$pmm + 1\n",
    "            cat(sprintf(\"  %s: pmm (numeric fallback)\\n\", col))\n",
    "          } else if(is.factor(historic_data[[col]]) || is.character(historic_data[[col]])) {\n",
    "            if(!is.factor(historic_data[[col]])) {\n",
    "              historic_data[[col]] <- as.factor(historic_data[[col]])\n",
    "            }\n",
    "            if(n_unique <= 10) {\n",
    "              impute_methods_historic[col] <- \"cart\"\n",
    "              method_counts$cart <- method_counts$cart + 1\n",
    "            } else if(n_unique <= 50) {\n",
    "              impute_methods_historic[col] <- \"polyreg\"\n",
    "              method_counts$polyreg <- method_counts$polyreg + 1\n",
    "            } else {\n",
    "              impute_methods_historic[col] <- \"sample\"\n",
    "              method_counts$sample <- method_counts$sample + 1\n",
    "            }\n",
    "            cat(sprintf(\"  %s: %s (categorical fallback, %d categories)\\n\", \n",
    "                        col, impute_methods_historic[col], n_unique))\n",
    "          } else if(is.logical(historic_data[[col]])) {\n",
    "            if(!is.factor(historic_data[[col]])) {\n",
    "              historic_data[[col]] <- as.factor(historic_data[[col]])\n",
    "            }\n",
    "            impute_methods_historic[col] <- \"logreg\"\n",
    "            method_counts$logreg <- method_counts$logreg + 1\n",
    "            cat(sprintf(\"  %s: logreg (logical fallback)\\n\", col))\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    cat(\"\\n[METHOD SUMMARY]\\n\")\n",
    "    cat(sprintf(\"  PMM: %d variables\\n\", method_counts$pmm))\n",
    "    cat(sprintf(\"  CART: %d variables\\n\", method_counts$cart))\n",
    "    cat(sprintf(\"  PolyReg: %d variables\\n\", method_counts$polyreg))\n",
    "    cat(sprintf(\"  Sample: %d variables\\n\", method_counts$sample))\n",
    "    cat(sprintf(\"  LogReg: %d variables\\n\", method_counts$logreg))\n",
    "    flush.console()\n",
    "\n",
    "    cat(\"\\n[PROGRESS] Starting MICE imputation on historic data...\\n\")\n",
    "    cat(sprintf(\"Timestamp: %s - This may take several minutes\\n\", Sys.time()))\n",
    "    cat(\"Note: Progress will update after each iteration completes\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    historic_mice <- mice(historic_data,\n",
    "                          m = 5,\n",
    "                          method = impute_methods_historic,\n",
    "                          predictorMatrix = pred_matrix_historic,\n",
    "                          ridge = 1e-5,\n",
    "                          maxit = 5,\n",
    "                          seed = 550,\n",
    "                          printFlag = TRUE)\n",
    "    \n",
    "    cat(\"\\n[PROGRESS] MICE imputation completed, extracting completed dataset...\\n\")\n",
    "    cat(sprintf(\"Timestamp: %s\\n\", Sys.time()))\n",
    "    flush.console()\n",
    "    \n",
    "    historic_data <- complete(historic_mice, 1)\n",
    "\n",
    "    if(length(numeric_missing_historic) > 0) {\n",
    "      post_stats_historic <- data.frame(\n",
    "        Variable = numeric_missing_historic,\n",
    "        Imputed_Mean = sapply(historic_data[numeric_missing_historic], mean, na.rm = TRUE),\n",
    "        Imputed_Median = sapply(historic_data[numeric_missing_historic], median, na.rm = TRUE),\n",
    "        Imputed_Variance = sapply(historic_data[numeric_missing_historic], var, na.rm = TRUE),\n",
    "        stringsAsFactors = FALSE\n",
    "      )\n",
    "      comparison_historic <- merge(original_stats_historic, post_stats_historic, by = \"Variable\")\n",
    "    }\n",
    "    \n",
    "    # Store post-imputation categorical distributions\n",
    "    if(length(categorical_missing_historic) > 0) {\n",
    "      post_cat_dist_historic <- list()\n",
    "      for(col in categorical_missing_historic) {\n",
    "        post_cat_dist_historic[[col]] <- prop.table(table(historic_data[[col]]))\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    # Store post-imputation boolean distributions\n",
    "    if(length(boolean_missing_historic) > 0) {\n",
    "      post_bool_dist_historic <- list()\n",
    "      for(col in boolean_missing_historic) {\n",
    "        post_bool_dist_historic[[col]] <- prop.table(table(historic_data[[col]]))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    cat(\"Historic data imputation complete\\n\")\n",
    "    cat(sprintf(\"Timestamp: %s\\n\", Sys.time()))\n",
    "    flush.console()\n",
    "  }\n",
    "\n",
    "  # Impute predict set\n",
    "  if(remaining_missing_predict > 0) {\n",
    "    cat(\"\\n--- Processing Predict Set ---\\n\")\n",
    "    cat(sprintf(\"Timestamp: %s\\n\", Sys.time()))\n",
    "    flush.console()\n",
    "    \n",
    "    cols_with_missing_predict <- names(predict_set)[colSums(is.na(predict_set)) > 0]\n",
    "    \n",
    "    cat(sprintf(\"[PROGRESS] Found %d columns with missing values\\n\", length(cols_with_missing_predict)))\n",
    "    flush.console()\n",
    "    \n",
    "    # Identify numeric columns with missing values for statistics tracking\n",
    "    numeric_missing_predict <- cols_with_missing_predict[\n",
    "      sapply(cols_with_missing_predict, function(col) {\n",
    "        col %in% names(cb_types$type) && codebook_col_type(col, cb_types) == \"Numeric\"\n",
    "      })\n",
    "    ]\n",
    "    \n",
    "    # Identify categorical columns with missing values for distribution tracking\n",
    "    categorical_missing_predict <- cols_with_missing_predict[\n",
    "      sapply(cols_with_missing_predict, function(col) {\n",
    "        col %in% names(cb_types$type) && codebook_col_type(col, cb_types) == \"Categorical\"\n",
    "      })\n",
    "    ]\n",
    "    \n",
    "    # Identify boolean columns with missing values for distribution tracking\n",
    "    boolean_missing_predict <- cols_with_missing_predict[\n",
    "      sapply(cols_with_missing_predict, function(col) {\n",
    "        col %in% names(cb_types$type) && codebook_col_type(col, cb_types) == \"Boolean\"\n",
    "      })\n",
    "    ]\n",
    "\n",
    "    cat(sprintf(\"[PROGRESS] Numeric: %d, Categorical: %d, Boolean: %d\\n\", \n",
    "                length(numeric_missing_predict), \n",
    "                length(categorical_missing_predict),\n",
    "                length(boolean_missing_predict)))\n",
    "    flush.console()\n",
    "\n",
    "    if(length(numeric_missing_predict) > 0) {\n",
    "      original_stats_predict <- data.frame(\n",
    "        Variable = numeric_missing_predict,\n",
    "        Original_Mean = sapply(predict_set[numeric_missing_predict], mean, na.rm = TRUE),\n",
    "        Original_Median = sapply(predict_set[numeric_missing_predict], median, na.rm = TRUE),\n",
    "        Original_Variance = sapply(predict_set[numeric_missing_predict], var, na.rm = TRUE),\n",
    "        stringsAsFactors = FALSE\n",
    "      )\n",
    "    }\n",
    "    \n",
    "    # Store original categorical distributions\n",
    "    if(length(categorical_missing_predict) > 0) {\n",
    "      original_cat_dist_predict <- list()\n",
    "      for(col in categorical_missing_predict) {\n",
    "        original_cat_dist_predict[[col]] <- prop.table(table(predict_set[[col]], useNA = \"no\"))\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    # Store original boolean distributions\n",
    "    if(length(boolean_missing_predict) > 0) {\n",
    "      original_bool_dist_predict <- list()\n",
    "      for(col in boolean_missing_predict) {\n",
    "        original_bool_dist_predict[[col]] <- prop.table(table(predict_set[[col]], useNA = \"no\"))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    cat(\"Variables with missing values:\", length(cols_with_missing_predict), \"\\n\")\n",
    "    \n",
    "    # Diagnostic: Analyze imputation complexity\n",
    "    cat(\"\\n=== Imputation Complexity Analysis (Predict Set) ===\\n\")\n",
    "    for(col in cols_with_missing_predict) {\n",
    "      n_missing <- sum(is.na(predict_set[[col]]))\n",
    "      n_unique <- length(unique(predict_set[[col]][!is.na(predict_set[[col]])]))\n",
    "      col_type <- class(predict_set[[col]])[1]\n",
    "      \n",
    "      cat(sprintf(\"%s: %d missing, %d unique values, type=%s\\n\",\n",
    "                  col, n_missing, n_unique, col_type))\n",
    "    }\n",
    "    flush.console()\n",
    "    \n",
    "    cat(\"\\n[PROGRESS] Creating predictor matrix with quickpred()...\\n\")\n",
    "    cat(sprintf(\"Timestamp: %s\\n\", Sys.time()))\n",
    "    flush.console()\n",
    "    \n",
    "    pred_matrix_predict <- quickpred(predict_set, mincor = 0.3, minpuc = 0.5)\n",
    "    \n",
    "    cat(\"[PROGRESS] Predictor matrix created successfully\\n\")\n",
    "    cat(sprintf(\"Timestamp: %s\\n\", Sys.time()))\n",
    "    flush.console()\n",
    "    \n",
    "    impute_methods_predict <- make.method(predict_set)\n",
    "\n",
    "    # Assign imputation methods based on codebook data types\n",
    "    cat(\"\\n=== Assigning Imputation Methods (Predict Set) ===\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    method_counts_predict <- list(pmm = 0, cart = 0, polyreg = 0, sample = 0, logreg = 0)\n",
    "    \n",
    "    for(col in names(predict_set)) {\n",
    "      if(sum(is.na(predict_set[[col]])) > 0) {\n",
    "        # Skip if column doesn't exist in codebook\n",
    "        if(!col %in% names(cb_types$type)) {\n",
    "          cat(sprintf(\"  %s: skipped (not in codebook)\\n\", col))\n",
    "          next\n",
    "        }\n",
    "        \n",
    "        col_type <- codebook_col_type(col, cb_types)\n",
    "        n_unique <- length(unique(predict_set[[col]][!is.na(predict_set[[col]])]))\n",
    "        \n",
    "        if(col_type == \"Numeric\") {\n",
    "          impute_methods_predict[col] <- \"pmm\"\n",
    "          method_counts_predict$pmm <- method_counts_predict$pmm + 1\n",
    "          cat(sprintf(\"  %s: pmm (numeric)\\n\", col))\n",
    "          \n",
    "        } else if(col_type == \"Categorical\") {\n",
    "          # Ensure it's a factor\n",
    "          if(!is.factor(predict_set[[col]])) {\n",
    "            predict_set[[col]] <- as.factor(predict_set[[col]])\n",
    "          }\n",
    "          \n",
    "          # Handle based on cardinality\n",
    "          if(n_unique <= 10) {\n",
    "            impute_methods_predict[col] <- \"cart\"\n",
    "            method_counts_predict$cart <- method_counts_predict$cart + 1\n",
    "            cat(sprintf(\"  %s: cart (%d categories)\\n\", col, n_unique))\n",
    "          } else if(n_unique <= 50) {\n",
    "            impute_methods_predict[col] <- \"polyreg\"\n",
    "            method_counts_predict$polyreg <- method_counts_predict$polyreg + 1\n",
    "            cat(sprintf(\"  %s: polyreg (%d categories)\\n\", col, n_unique))\n",
    "          } else {\n",
    "            impute_methods_predict[col] <- \"sample\"\n",
    "            method_counts_predict$sample <- method_counts_predict$sample + 1\n",
    "            cat(sprintf(\"  %s: sample (%d categories - too many for polyreg)\\n\", col, n_unique))\n",
    "          }\n",
    "          \n",
    "        } else if(col_type == \"Boolean\") {\n",
    "          # Ensure it's a factor for logreg\n",
    "          if(!is.factor(predict_set[[col]])) {\n",
    "            predict_set[[col]] <- as.factor(predict_set[[col]])\n",
    "          }\n",
    "          impute_methods_predict[col] <- \"logreg\"\n",
    "          method_counts_predict$logreg <- method_counts_predict$logreg + 1\n",
    "          cat(sprintf(\"  %s: logreg (boolean)\\n\", col))\n",
    "          \n",
    "        } else {\n",
    "          # Fallback for unknown types\n",
    "          if(is.numeric(predict_set[[col]])) {\n",
    "            impute_methods_predict[col] <- \"pmm\"\n",
    "            method_counts_predict$pmm <- method_counts_predict$pmm + 1\n",
    "            cat(sprintf(\"  %s: pmm (numeric fallback)\\n\", col))\n",
    "          } else if(is.factor(predict_set[[col]]) || is.character(predict_set[[col]])) {\n",
    "            if(!is.factor(predict_set[[col]])) {\n",
    "              predict_set[[col]] <- as.factor(predict_set[[col]])\n",
    "            }\n",
    "            if(n_unique <= 10) {\n",
    "              impute_methods_predict[col] <- \"cart\"\n",
    "              method_counts_predict$cart <- method_counts_predict$cart + 1\n",
    "            } else if(n_unique <= 50) {\n",
    "              impute_methods_predict[col] <- \"polyreg\"\n",
    "              method_counts_predict$polyreg <- method_counts_predict$polyreg + 1\n",
    "            } else {\n",
    "              impute_methods_predict[col] <- \"sample\"\n",
    "              method_counts_predict$sample <- method_counts_predict$sample + 1\n",
    "            }\n",
    "            cat(sprintf(\"  %s: %s (categorical fallback, %d categories)\\n\", \n",
    "                        col, impute_methods_predict[col], n_unique))\n",
    "          } else if(is.logical(predict_set[[col]])) {\n",
    "            if(!is.factor(predict_set[[col]])) {\n",
    "              predict_set[[col]] <- as.factor(predict_set[[col]])\n",
    "            }\n",
    "            impute_methods_predict[col] <- \"logreg\"\n",
    "            method_counts_predict$logreg <- method_counts_predict$logreg + 1\n",
    "            cat(sprintf(\"  %s: logreg (logical fallback)\\n\", col))\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    cat(\"\\n[METHOD SUMMARY]\\n\")\n",
    "    cat(sprintf(\"  PMM: %d variables\\n\", method_counts_predict$pmm))\n",
    "    cat(sprintf(\"  CART: %d variables\\n\", method_counts_predict$cart))\n",
    "    cat(sprintf(\"  PolyReg: %d variables\\n\", method_counts_predict$polyreg))\n",
    "    cat(sprintf(\"  Sample: %d variables\\n\", method_counts_predict$sample))\n",
    "    cat(sprintf(\"  LogReg: %d variables\\n\", method_counts_predict$logreg))\n",
    "    flush.console()\n",
    "\n",
    "    cat(\"\\n[PROGRESS] Starting MICE imputation on predict set...\\n\")\n",
    "    cat(sprintf(\"Timestamp: %s - This may take several minutes\\n\", Sys.time()))\n",
    "    cat(\"Note: Progress will update after each iteration completes\\n\")\n",
    "    flush.console()\n",
    "    \n",
    "    predict_mice <- mice(predict_set,\n",
    "                         m = 5,\n",
    "                         method = impute_methods_predict,\n",
    "                         predictorMatrix = pred_matrix_predict,\n",
    "                         ridge = 1e-5,\n",
    "                         maxit = 5,\n",
    "                         seed = 550,\n",
    "                         printFlag = TRUE)\n",
    "    \n",
    "    cat(\"\\n[PROGRESS] MICE imputation completed, extracting completed dataset...\\n\")\n",
    "    cat(sprintf(\"Timestamp: %s\\n\", Sys.time()))\n",
    "    flush.console()\n",
    "    \n",
    "    predict_set <- complete(predict_mice, 1)\n",
    "\n",
    "    if(length(numeric_missing_predict) > 0) {\n",
    "      post_stats_predict <- data.frame(\n",
    "        Variable = numeric_missing_predict,\n",
    "        Imputed_Mean = sapply(predict_set[numeric_missing_predict], mean, na.rm = TRUE),\n",
    "        Imputed_Median = sapply(predict_set[numeric_missing_predict], median, na.rm = TRUE),\n",
    "        Imputed_Variance = sapply(predict_set[numeric_missing_predict], var, na.rm = TRUE),\n",
    "        stringsAsFactors = FALSE\n",
    "      )\n",
    "      comparison_predict <- merge(original_stats_predict, post_stats_predict, by = \"Variable\")\n",
    "    }\n",
    "    \n",
    "    # Store post-imputation categorical distributions\n",
    "    if(length(categorical_missing_predict) > 0) {\n",
    "      post_cat_dist_predict <- list()\n",
    "      for(col in categorical_missing_predict) {\n",
    "        post_cat_dist_predict[[col]] <- prop.table(table(predict_set[[col]]))\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    # Store post-imputation boolean distributions\n",
    "    if(length(boolean_missing_predict) > 0) {\n",
    "      post_bool_dist_predict <- list()\n",
    "      for(col in boolean_missing_predict) {\n",
    "        post_bool_dist_predict[[col]] <- prop.table(table(predict_set[[col]]))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    cat(\"Predict set imputation complete\\n\")\n",
    "    cat(sprintf(\"Timestamp: %s\\n\", Sys.time()))\n",
    "    flush.console()\n",
    "  }\n",
    "\n",
    "  # Create comparison plots showing percent difference (only for numeric variables)\n",
    "  cat(\"\\n=== Creating Imputation Comparison Plots ===\\n\")\n",
    "  cat(sprintf(\"Timestamp: %s\\n\", Sys.time()))\n",
    "  flush.console()\n",
    "\n",
    "  if(remaining_missing_historic > 0 && exists(\"comparison_historic\") && nrow(comparison_historic) > 0) {\n",
    "    comparison_historic_pct <- comparison_historic %>%\n",
    "      mutate(\n",
    "        Mean_Pct_Diff = ((Imputed_Mean - Original_Mean) / abs(Original_Mean)) * 100,\n",
    "        Median_Pct_Diff = ((Imputed_Median - Original_Median) / abs(Original_Median)) * 100,\n",
    "        Variance_Pct_Diff = ((Imputed_Variance - Original_Variance) / abs(Original_Variance)) * 100\n",
    "      ) %>%\n",
    "      select(Variable, Mean_Pct_Diff, Median_Pct_Diff, Variance_Pct_Diff)\n",
    "    comparison_historic_pct[sapply(comparison_historic_pct, is.infinite)] <- NA\n",
    "    comparison_long_historic <- comparison_historic_pct %>%\n",
    "      pivot_longer(cols = -Variable,\n",
    "                   names_to = \"Statistic\",\n",
    "                   names_pattern = \"(.*)_Pct_Diff\",\n",
    "                   values_to = \"Percent_Difference\") %>%\n",
    "      filter(!is.na(Percent_Difference) & is.finite(Percent_Difference))\n",
    "\n",
    "    if(nrow(comparison_long_historic) > 0) {\n",
    "      p_historic <- ggplot(comparison_long_historic,\n",
    "                           aes(x = Variable, y = Percent_Difference, fill = Statistic)) +\n",
    "        geom_bar(stat = \"identity\", position = \"dodge\") +\n",
    "        geom_hline(yintercept = 0, linetype = \"dashed\", color = \"black\") +\n",
    "        facet_wrap(~Statistic, scales = \"free_y\", ncol = 1) +\n",
    "        theme_minimal() +\n",
    "        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n",
    "        labs(title = \"Historic Data: % Difference in Statistics After Imputation\",\n",
    "             subtitle = \"MICE (PMM/CART/PolyReg/Sample/LogReg)\",\n",
    "             x = \"Variable\",\n",
    "             y = \"Percent Difference (%)\",\n",
    "             fill = \"Statistic\") +\n",
    "        scale_fill_manual(values = c(\"Mean\" = \"#E69F00\", \"Median\" = \"#56B4E9\", \"Variance\" = \"#009E73\"))\n",
    "\n",
    "      print(p_historic)\n",
    "    }\n",
    "  }\n",
    "\n",
    "  if(remaining_missing_predict > 0 && exists(\"comparison_predict\") && nrow(comparison_predict) > 0) {\n",
    "    comparison_predict_pct <- comparison_predict %>%\n",
    "      mutate(\n",
    "        Mean_Pct_Diff = ((Imputed_Mean - Original_Mean) / abs(Original_Mean)) * 100,\n",
    "        Median_Pct_Diff = ((Imputed_Median - Original_Median) / abs(Original_Median)) * 100,\n",
    "        Variance_Pct_Diff = ((Imputed_Variance - Original_Variance) / abs(Original_Variance)) * 100\n",
    "      ) %>%\n",
    "      select(Variable, Mean_Pct_Diff, Median_Pct_Diff, Variance_Pct_Diff)\n",
    "    comparison_predict_pct[sapply(comparison_predict_pct, is.infinite)] <- NA\n",
    "    comparison_long_predict <- comparison_predict_pct %>%\n",
    "      pivot_longer(cols = -Variable,\n",
    "                   names_to = \"Statistic\",\n",
    "                   names_pattern = \"(.*)_Pct_Diff\",\n",
    "                   values_to = \"Percent_Difference\") %>%\n",
    "      filter(!is.na(Percent_Difference) & is.finite(Percent_Difference))\n",
    "\n",
    "    if(nrow(comparison_long_predict) > 0) {\n",
    "      p_predict <- ggplot(comparison_long_predict,\n",
    "                          aes(x = Variable, y = Percent_Difference, fill = Statistic)) +\n",
    "        geom_bar(stat = \"identity\", position = \"dodge\") +\n",
    "        geom_hline(yintercept = 0, linetype = \"dashed\", color = \"black\") +\n",
    "        facet_wrap(~Statistic, scales = \"free_y\", ncol = 1) +\n",
    "        theme_minimal() +\n",
    "        theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n",
    "        labs(title = \"Predict Set: % Difference in Statistics After Imputation\",\n",
    "             subtitle = \"MICE (PMM/CART/PolyReg/Sample/LogReg)\",\n",
    "             x = \"Variable\",\n",
    "             y = \"Percent Difference (%)\",\n",
    "             fill = \"Statistic\") +\n",
    "        scale_fill_manual(values = c(\"Mean\" = \"#E69F00\", \"Median\" = \"#56B4E9\", \"Variance\" = \"#009E73\"))\n",
    "\n",
    "      print(p_predict)\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Categorical and Boolean Distribution Comparison\n",
    "  cat(\"\\n=== Categorical and Boolean Distribution Preservation ===\\n\")\n",
    "  \n",
    "  # Historic Data - Categorical Variables\n",
    "  if(remaining_missing_historic > 0 && exists(\"original_cat_dist_historic\") && length(original_cat_dist_historic) > 0) {\n",
    "    cat(\"\\n--- Historic Data: Categorical Variables ---\\n\")\n",
    "    \n",
    "    cat_comparison_historic <- data.frame()\n",
    "    for(col in names(original_cat_dist_historic)) {\n",
    "      orig_dist <- original_cat_dist_historic[[col]]\n",
    "      post_dist <- post_cat_dist_historic[[col]]\n",
    "      \n",
    "      # Align categories\n",
    "      all_categories <- union(names(orig_dist), names(post_dist))\n",
    "      orig_aligned <- sapply(all_categories, function(cat) {\n",
    "        ifelse(cat %in% names(orig_dist), orig_dist[cat], 0)\n",
    "      })\n",
    "      post_aligned <- sapply(all_categories, function(cat) {\n",
    "        ifelse(cat %in% names(post_dist), post_dist[cat], 0)\n",
    "      })\n",
    "      \n",
    "      # Calculate absolute difference in proportions\n",
    "      for(i in seq_along(all_categories)) {\n",
    "        cat_comparison_historic <- rbind(cat_comparison_historic, data.frame(\n",
    "          Variable = col,\n",
    "          Category = all_categories[i],\n",
    "          Original_Prop = orig_aligned[i],\n",
    "          Imputed_Prop = post_aligned[i],\n",
    "          Abs_Diff = abs(post_aligned[i] - orig_aligned[i]),\n",
    "          stringsAsFactors = FALSE\n",
    "        ))\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    # Print summary statistics\n",
    "    cat(\"Maximum absolute difference in category proportions:\", \n",
    "        sprintf(\"%.4f\", max(cat_comparison_historic$Abs_Diff)), \"\\n\")\n",
    "    cat(\"Mean absolute difference in category proportions:\", \n",
    "        sprintf(\"%.4f\", mean(cat_comparison_historic$Abs_Diff)), \"\\n\")\n",
    "    \n",
    "    # Create visualization (only for variables with ≤10 categories for readability)\n",
    "    cat_vars_to_plot <- names(original_cat_dist_historic)[\n",
    "      sapply(names(original_cat_dist_historic), function(v) {\n",
    "        length(unique(historic_data[[v]])) <= 10\n",
    "      })\n",
    "    ]\n",
    "    \n",
    "    if(length(cat_vars_to_plot) > 0) {\n",
    "      cat_comparison_long_historic <- cat_comparison_historic %>%\n",
    "        filter(Variable %in% cat_vars_to_plot) %>%\n",
    "        pivot_longer(cols = c(Original_Prop, Imputed_Prop),\n",
    "                     names_to = \"Distribution\",\n",
    "                     values_to = \"Proportion\") %>%\n",
    "        mutate(Distribution = ifelse(Distribution == \"Original_Prop\", \"Pre-Imputation\", \"Post-Imputation\"))\n",
    "      \n",
    "      p_cat_historic <- ggplot(cat_comparison_long_historic,\n",
    "                               aes(x = Category, y = Proportion, fill = Distribution)) +\n",
    "        geom_bar(stat = \"identity\", position = \"dodge\") +\n",
    "        facet_wrap(~Variable, scales = \"free_x\", ncol = 2) +\n",
    "        theme_minimal() +\n",
    "        theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n",
    "              legend.position = \"bottom\") +\n",
    "        labs(title = \"Historic Data: Categorical Distribution Preservation\",\n",
    "             subtitle = \"Comparison of category proportions (low-cardinality variables only)\",\n",
    "             x = \"Category\",\n",
    "             y = \"Proportion\",\n",
    "             fill = \"\") +\n",
    "        scale_fill_manual(values = c(\"Pre-Imputation\" = \"#0072B2\", \"Post-Imputation\" = \"#D55E00\"))\n",
    "      \n",
    "      print(p_cat_historic)\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Historic Data - Boolean Variables\n",
    "  if(remaining_missing_historic > 0 && exists(\"original_bool_dist_historic\") && length(original_bool_dist_historic) > 0) {\n",
    "    cat(\"\\n--- Historic Data: Boolean Variables ---\\n\")\n",
    "    \n",
    "    bool_comparison_historic <- data.frame()\n",
    "    for(col in names(original_bool_dist_historic)) {\n",
    "      orig_dist <- original_bool_dist_historic[[col]]\n",
    "      post_dist <- post_bool_dist_historic[[col]]\n",
    "      \n",
    "      # Align categories\n",
    "      all_categories <- union(names(orig_dist), names(post_dist))\n",
    "      orig_aligned <- sapply(all_categories, function(cat) {\n",
    "        ifelse(cat %in% names(orig_dist), orig_dist[cat], 0)\n",
    "      })\n",
    "      post_aligned <- sapply(all_categories, function(cat) {\n",
    "        ifelse(cat %in% names(post_dist), post_dist[cat], 0)\n",
    "      })\n",
    "      \n",
    "      # Calculate absolute difference in proportions\n",
    "      for(i in seq_along(all_categories)) {\n",
    "        bool_comparison_historic <- rbind(bool_comparison_historic, data.frame(\n",
    "          Variable = col,\n",
    "          Category = all_categories[i],\n",
    "          Original_Prop = orig_aligned[i],\n",
    "          Imputed_Prop = post_aligned[i],\n",
    "          Abs_Diff = abs(post_aligned[i] - orig_aligned[i]),\n",
    "          stringsAsFactors = FALSE\n",
    "        ))\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    # Print summary statistics\n",
    "    cat(\"Maximum absolute difference in boolean proportions:\", \n",
    "        sprintf(\"%.4f\", max(bool_comparison_historic$Abs_Diff)), \"\\n\")\n",
    "    cat(\"Mean absolute difference in boolean proportions:\", \n",
    "        sprintf(\"%.4f\", mean(bool_comparison_historic$Abs_Diff)), \"\\n\")\n",
    "    \n",
    "    # Create visualization\n",
    "    bool_comparison_long_historic <- bool_comparison_historic %>%\n",
    "      pivot_longer(cols = c(Original_Prop, Imputed_Prop),\n",
    "                   names_to = \"Distribution\",\n",
    "                   values_to = \"Proportion\") %>%\n",
    "      mutate(Distribution = ifelse(Distribution == \"Original_Prop\", \"Pre-Imputation\", \"Post-Imputation\"))\n",
    "    \n",
    "    p_bool_historic <- ggplot(bool_comparison_long_historic,\n",
    "                              aes(x = Category, y = Proportion, fill = Distribution)) +\n",
    "      geom_bar(stat = \"identity\", position = \"dodge\") +\n",
    "      facet_wrap(~Variable, scales = \"free_x\", ncol = 2) +\n",
    "      theme_minimal() +\n",
    "      theme(axis.text.x = element_text(angle = 45, hjust = 1),\n",
    "            legend.position = \"bottom\") +\n",
    "      labs(title = \"Historic Data: Boolean Distribution Preservation (LogReg)\",\n",
    "           subtitle = \"Comparison of TRUE/FALSE proportions before and after MICE imputation\",\n",
    "           x = \"Value\",\n",
    "           y = \"Proportion\",\n",
    "           fill = \"\") +\n",
    "      scale_fill_manual(values = c(\"Pre-Imputation\" = \"#0072B2\", \"Post-Imputation\" = \"#D55E00\"))\n",
    "    \n",
    "    print(p_bool_historic)\n",
    "  }\n",
    "  \n",
    "  # Predict Set - Categorical Variables\n",
    "  if(remaining_missing_predict > 0 && exists(\"original_cat_dist_predict\") && length(original_cat_dist_predict) > 0) {\n",
    "    cat(\"\\n--- Predict Set: Categorical Variables ---\\n\")\n",
    "    \n",
    "    cat_comparison_predict <- data.frame()\n",
    "    for(col in names(original_cat_dist_predict)) {\n",
    "      orig_dist <- original_cat_dist_predict[[col]]\n",
    "      post_dist <- post_cat_dist_predict[[col]]\n",
    "      \n",
    "      # Align categories\n",
    "      all_categories <- union(names(orig_dist), names(post_dist))\n",
    "      orig_aligned <- sapply(all_categories, function(cat) {\n",
    "        ifelse(cat %in% names(orig_dist), orig_dist[cat], 0)\n",
    "      })\n",
    "      post_aligned <- sapply(all_categories, function(cat) {\n",
    "        ifelse(cat %in% names(post_dist), post_dist[cat], 0)\n",
    "      })\n",
    "      \n",
    "      # Calculate absolute difference in proportions\n",
    "      for(i in seq_along(all_categories)) {\n",
    "        cat_comparison_predict <- rbind(cat_comparison_predict, data.frame(\n",
    "          Variable = col,\n",
    "          Category = all_categories[i],\n",
    "          Original_Prop = orig_aligned[i],\n",
    "          Imputed_Prop = post_aligned[i],\n",
    "          Abs_Diff = abs(post_aligned[i] - orig_aligned[i]),\n",
    "          stringsAsFactors = FALSE\n",
    "        ))\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    # Print summary statistics\n",
    "    cat(\"Maximum absolute difference in category proportions:\", \n",
    "        sprintf(\"%.4f\", max(cat_comparison_predict$Abs_Diff)), \"\\n\")\n",
    "    cat(\"Mean absolute difference in category proportions:\", \n",
    "        sprintf(\"%.4f\", mean(cat_comparison_predict$Abs_Diff)), \"\\n\")\n",
    "    \n",
    "    # Create visualization (only for variables with ≤10 categories for readability)\n",
    "    cat_vars_to_plot <- names(original_cat_dist_predict)[\n",
    "      sapply(names(original_cat_dist_predict), function(v) {\n",
    "        length(unique(predict_set[[v]])) <= 10\n",
    "      })\n",
    "    ]\n",
    "    \n",
    "    if(length(cat_vars_to_plot) > 0) {\n",
    "      cat_comparison_long_predict <- cat_comparison_predict %>%\n",
    "        filter(Variable %in% cat_vars_to_plot) %>%\n",
    "        pivot_longer(cols = c(Original_Prop, Imputed_Prop),\n",
    "                     names_to = \"Distribution\",\n",
    "                     values_to = \"Proportion\") %>%\n",
    "        mutate(Distribution = ifelse(Distribution == \"Original_Prop\", \"Pre-Imputation\", \"Post-Imputation\"))\n",
    "      \n",
    "      p_cat_predict <- ggplot(cat_comparison_long_predict,\n",
    "                              aes(x = Category, y = Proportion, fill = Distribution)) +\n",
    "        geom_bar(stat = \"identity\", position = \"dodge\") +\n",
    "        facet_wrap(~Variable, scales = \"free_x\", ncol = 2) +\n",
    "        theme_minimal() +\n",
    "        theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n",
    "              legend.position = \"bottom\") +\n",
    "        labs(title = \"Predict Set: Categorical Distribution Preservation\",\n",
    "             subtitle = \"Comparison of category proportions (low-cardinality variables only)\",\n",
    "             x = \"Category\",\n",
    "             y = \"Proportion\",\n",
    "             fill = \"\") +\n",
    "        scale_fill_manual(values = c(\"Pre-Imputation\" = \"#0072B2\", \"Post-Imputation\" = \"#D55E00\"))\n",
    "      \n",
    "      print(p_cat_predict)\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Predict Set - Boolean Variables\n",
    "  if(remaining_missing_predict > 0 && exists(\"original_bool_dist_predict\") && length(original_bool_dist_predict) > 0) {\n",
    "    cat(\"\\n--- Predict Set: Boolean Variables ---\\n\")\n",
    "    \n",
    "    bool_comparison_predict <- data.frame()\n",
    "    for(col in names(original_bool_dist_predict)) {\n",
    "      orig_dist <- original_bool_dist_predict[[col]]\n",
    "      post_dist <- post_bool_dist_predict[[col]]\n",
    "      \n",
    "      # Align categories\n",
    "      all_categories <- union(names(orig_dist), names(post_dist))\n",
    "      orig_aligned <- sapply(all_categories, function(cat) {\n",
    "        ifelse(cat %in% names(orig_dist), orig_dist[cat], 0)\n",
    "      })\n",
    "      post_aligned <- sapply(all_categories, function(cat) {\n",
    "        ifelse(cat %in% names(post_dist), post_dist[cat], 0)\n",
    "      })\n",
    "      \n",
    "      # Calculate absolute difference in proportions\n",
    "      for(i in seq_along(all_categories)) {\n",
    "        bool_comparison_predict <- rbind(bool_comparison_predict, data.frame(\n",
    "          Variable = col,\n",
    "          Category = all_categories[i],\n",
    "          Original_Prop = orig_aligned[i],\n",
    "          Imputed_Prop = post_aligned[i],\n",
    "          Abs_Diff = abs(post_aligned[i] - orig_aligned[i]),\n",
    "          stringsAsFactors = FALSE\n",
    "        ))\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    # Print summary statistics\n",
    "    cat(\"Maximum absolute difference in boolean proportions:\", \n",
    "        sprintf(\"%.4f\", max(bool_comparison_predict$Abs_Diff)), \"\\n\")\n",
    "    cat(\"Mean absolute difference in boolean proportions:\", \n",
    "        sprintf(\"%.4f\", mean(bool_comparison_predict$Abs_Diff)), \"\\n\")\n",
    "    \n",
    "    # Create visualization\n",
    "    bool_comparison_long_predict <- bool_comparison_predict %>%\n",
    "      pivot_longer(cols = c(Original_Prop, Imputed_Prop),\n",
    "                   names_to = \"Distribution\",\n",
    "                   values_to = \"Proportion\") %>%\n",
    "      mutate(Distribution = ifelse(Distribution == \"Original_Prop\", \"Pre-Imputation\", \"Post-Imputation\"))\n",
    "    \n",
    "    p_bool_predict <- ggplot(bool_comparison_long_predict,\n",
    "                             aes(x = Category, y = Proportion, fill = Distribution)) +\n",
    "      geom_bar(stat = \"identity\", position = \"dodge\") +\n",
    "      facet_wrap(~Variable, scales = \"free_x\", ncol = 2) +\n",
    "      theme_minimal() +\n",
    "      theme(axis.text.x = element_text(angle = 45, hjust = 1),\n",
    "            legend.position = \"bottom\") +\n",
    "      labs(title = \"Predict Set: Boolean Distribution Preservation (LogReg)\",\n",
    "           subtitle = \"Comparison of TRUE/FALSE proportions before and after MICE imputation\",\n",
    "           x = \"Value\",\n",
    "           y = \"Proportion\",\n",
    "           fill = \"\") +\n",
    "      scale_fill_manual(values = c(\"Pre-Imputation\" = \"#0072B2\", \"Post-Imputation\" = \"#D55E00\"))\n",
    "    \n",
    "    print(p_bool_predict)\n",
    "  }\n",
    "\n",
    "  # Final verification\n",
    "  cat(\"\\n=== Post-Imputation Verification ===\\n\")\n",
    "  final_missing_historic <- sum(is.na(historic_data))\n",
    "  final_missing_predict <- sum(is.na(predict_set))\n",
    "\n",
    "  cat(\"Missing values in historic data:\", final_missing_historic, \"\\n\")\n",
    "  cat(\"Missing values in predict set:\", final_missing_predict, \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da144d5",
   "metadata": {},
   "source": [
    "---\n",
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3e8564",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# ENHANCED VARIABLE CLASSIFICATION\n",
    "# =====================================================\n",
    "\n",
    "cat(\"\\n=== Classifying Variables by Data Type ===\\n\")\n",
    "\n",
    "# Get codebook types\n",
    "cb_types <- get_codebook_types()\n",
    "\n",
    "# Classification function with granular types\n",
    "classify_variable <- function(var, data, cb_types) {\n",
    "  # Get codebook info\n",
    "  cb_type <- codebook_col_type(var, cb_types)\n",
    "  \n",
    "  # Get R data type\n",
    "  r_type <- class(data[[var]])[1]\n",
    "  \n",
    "  # Determine granular classification\n",
    "  if(cb_type == \"Numeric\") {\n",
    "    # Check if it's integer-like (whole numbers, counts) or continuous\n",
    "    if(r_type %in% c(\"integer\", \"factor\")) {\n",
    "      return(\"Integer\")\n",
    "    } else if(is.numeric(data[[var]])) {\n",
    "      # Check if values are mostly whole numbers (counts/discrete)\n",
    "      non_na_vals <- data[[var]][!is.na(data[[var]])]\n",
    "      if(length(non_na_vals) > 0) {\n",
    "        whole_number_pct <- mean(non_na_vals == floor(non_na_vals))\n",
    "        # If variable name suggests count (beds, rooms, baths) or >95% whole numbers\n",
    "        is_count <- grepl(\"beds|rooms|bath|apts|frpl\", var, ignore.case = TRUE)\n",
    "        if(is_count || whole_number_pct > 0.95) {\n",
    "          return(\"Integer\")\n",
    "        } else {\n",
    "          return(\"Continuous\")\n",
    "        }\n",
    "      }\n",
    "      return(\"Continuous\")\n",
    "    }\n",
    "  } else if(cb_type == \"Categorical\") {\n",
    "    # Check if ordinal (quality, condition, size ratings)\n",
    "    is_ordinal <- grepl(\"qlty|quality|cnd|condition|size|rating|grade\", var, ignore.case = TRUE)\n",
    "    if(is_ordinal) {\n",
    "      return(\"Ordinal\")\n",
    "    } else {\n",
    "      return(\"Nominal\")\n",
    "    }\n",
    "  } else if(cb_type == \"Boolean\") {\n",
    "    return(\"Boolean\")\n",
    "  }\n",
    "  \n",
    "  return(\"Unknown\")\n",
    "}\n",
    "\n",
    "# Classify all variables\n",
    "variable_classifications <- data.frame(\n",
    "  Variable = names(historic_data),\n",
    "  Classification = sapply(names(historic_data), function(v) {\n",
    "    classify_variable(v, historic_data, cb_types)\n",
    "  }),\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "\n",
    "# Group variables by classification\n",
    "integer_vars <- variable_classifications %>% filter(Classification == \"Integer\") %>% pull(Variable)\n",
    "continuous_vars <- variable_classifications %>% filter(Classification == \"Continuous\") %>% pull(Variable)\n",
    "ordinal_vars <- variable_classifications %>% filter(Classification == \"Ordinal\") %>% pull(Variable)\n",
    "nominal_vars <- variable_classifications %>% filter(Classification == \"Nominal\") %>% pull(Variable)\n",
    "boolean_vars <- variable_classifications %>% filter(Classification == \"Boolean\") %>% pull(Variable)\n",
    "\n",
    "cat(\"\\nVariable Classification Summary:\\n\")\n",
    "cat(\"  Integer Variables:\", length(integer_vars), \"\\n\")\n",
    "cat(\"  Continuous Variables:\", length(continuous_vars), \"\\n\")\n",
    "cat(\"  Ordinal Variables:\", length(ordinal_vars), \"\\n\")\n",
    "cat(\"  Nominal Variables:\", length(nominal_vars), \"\\n\")\n",
    "cat(\"  Boolean Variables:\", length(boolean_vars), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40bfbc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# SUMMARY STATISTICS BY CLASSIFICATION\n",
    "# =====================================================\n",
    "\n",
    "cat(\"\\n=== Summary Statistics ===\\n\\n\")\n",
    "\n",
    "# Integer variables\n",
    "if(length(integer_vars) > 0) {\n",
    "  cat(\"--- Integer Variables ---\\n\")\n",
    "  integer_stats <- historic_data %>%\n",
    "    select(all_of(integer_vars)) %>%\n",
    "    summarise(across(everything(), \n",
    "                     list(mean = ~mean(.x, na.rm = TRUE),\n",
    "                          median = ~median(.x, na.rm = TRUE),\n",
    "                          sd = ~sd(.x, na.rm = TRUE),\n",
    "                          variance = ~var(.x, na.rm = TRUE),\n",
    "                          min = ~min(.x, na.rm = TRUE),\n",
    "                          max = ~max(.x, na.rm = TRUE)),\n",
    "                     .names = \"{.col}_{.fn}\")) %>%\n",
    "    pivot_longer(everything(),\n",
    "                 names_to = c(\"Variable\", \"Statistic\"),\n",
    "                 names_pattern = \"(.*)_(mean|median|sd|variance|min|max)\",\n",
    "                 values_to = \"Value\") %>%\n",
    "    pivot_wider(names_from = Statistic, values_from = Value)\n",
    "  \n",
    "  print(integer_stats, n = Inf)\n",
    "}\n",
    "\n",
    "# Continuous variables\n",
    "if(length(continuous_vars) > 0) {\n",
    "  cat(\"\\n--- Continuous Variables ---\\n\")\n",
    "  continuous_stats <- historic_data %>%\n",
    "    select(all_of(continuous_vars)) %>%\n",
    "    summarise(across(everything(), \n",
    "                     list(mean = ~mean(.x, na.rm = TRUE),\n",
    "                          median = ~median(.x, na.rm = TRUE),\n",
    "                          sd = ~sd(.x, na.rm = TRUE),\n",
    "                          variance = ~var(.x, na.rm = TRUE),\n",
    "                          min = ~min(.x, na.rm = TRUE),\n",
    "                          max = ~max(.x, na.rm = TRUE)),\n",
    "                     .names = \"{.col}_{.fn}\")) %>%\n",
    "    pivot_longer(everything(),\n",
    "                 names_to = c(\"Variable\", \"Statistic\"),\n",
    "                 names_pattern = \"(.*)_(mean|median|sd|variance|min|max)\",\n",
    "                 values_to = \"Value\") %>%\n",
    "    pivot_wider(names_from = Statistic, values_from = Value)\n",
    "  \n",
    "  print(continuous_stats, n = Inf)\n",
    "}\n",
    "\n",
    "# Ordinal variables - NUMERIC TREATMENT\n",
    "if(length(ordinal_vars) > 0) {\n",
    "  cat(\"\\n--- Ordinal Variables (Numeric Statistics) ---\\n\")\n",
    "  \n",
    "  # Convert ordinal to numeric for statistics\n",
    "  ordinal_numeric <- historic_data %>%\n",
    "    select(all_of(ordinal_vars)) %>%\n",
    "    mutate(across(everything(), ~as.numeric(as.factor(.x))))\n",
    "  \n",
    "  ordinal_stats <- ordinal_numeric %>%\n",
    "    summarise(across(everything(), \n",
    "                     list(mean = ~mean(.x, na.rm = TRUE),\n",
    "                          median = ~median(.x, na.rm = TRUE),\n",
    "                          sd = ~sd(.x, na.rm = TRUE),\n",
    "                          variance = ~var(.x, na.rm = TRUE),\n",
    "                          min = ~min(.x, na.rm = TRUE),\n",
    "                          max = ~max(.x, na.rm = TRUE)),\n",
    "                     .names = \"{.col}_{.fn}\")) %>%\n",
    "    pivot_longer(everything(),\n",
    "                 names_to = c(\"Variable\", \"Statistic\"),\n",
    "                 names_pattern = \"(.*)_(mean|median|sd|variance|min|max)\",\n",
    "                 values_to = \"Value\") %>%\n",
    "    pivot_wider(names_from = Statistic, values_from = Value)\n",
    "  \n",
    "  print(ordinal_stats, n = Inf)\n",
    "  \n",
    "  cat(\"\\n--- Ordinal Variables (Category Distributions) ---\\n\")\n",
    "  for(var in head(ordinal_vars, 8)) {\n",
    "    cat(\"\\n\", var, \":\\n\", sep = \"\")\n",
    "    freq_table <- table(historic_data[[var]], useNA = \"no\")\n",
    "    freq_pct <- prop.table(freq_table) * 100\n",
    "    \n",
    "    for(i in seq_along(freq_pct)) {\n",
    "      cat(sprintf(\"  %s: %d (%.1f%%)\\n\", names(freq_pct)[i], freq_table[i], freq_pct[i]))\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Nominal summaries\n",
    "if(length(nominal_vars) > 0) {\n",
    "  cat(\"\\n--- Nominal Variables (Top Categories) ---\\n\")\n",
    "  for(var in head(nominal_vars, 5)) {\n",
    "    cat(\"\\n\", var, \":\\n\", sep = \"\")\n",
    "    freq_table <- table(historic_data[[var]], useNA = \"no\")\n",
    "    cat(\"  Unique values:\", length(freq_table), \"\\n\")\n",
    "    freq_pct <- prop.table(freq_table) * 100\n",
    "    top_3 <- head(sort(freq_pct, decreasing = TRUE), 3)\n",
    "    for(i in seq_along(top_3)) {\n",
    "      cat(sprintf(\"  %s: %d (%.1f%%)\\n\", names(top_3)[i], freq_table[names(top_3)[i]], top_3[i]))\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Boolean summaries\n",
    "if(length(boolean_vars) > 0) {\n",
    "  cat(\"\\n--- Boolean Variables ---\\n\")\n",
    "  for(var in boolean_vars) {\n",
    "    if(var %in% names(historic_data)) {\n",
    "      true_count <- sum(historic_data[[var]], na.rm = TRUE)\n",
    "      total_count <- sum(!is.na(historic_data[[var]]))\n",
    "      true_pct <- (true_count / total_count) * 100\n",
    "      cat(sprintf(\"  %s: TRUE=%d (%.1f%%), FALSE=%d (%.1f%%)\\n\",\n",
    "                  var, true_count, true_pct, total_count - true_count, 100 - true_pct))\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6987478",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# INTEGER VARIABLES: HISTOGRAMS\n",
    "# =====================================================\n",
    "\n",
    "cat(\"\\n=== Integer Variable Distributions (Histograms) ===\\n\")\n",
    "\n",
    "if(length(integer_vars) > 0) {\n",
    "  \n",
    "  for(var in integer_vars[1:min(8, length(integer_vars))]) {\n",
    "    \n",
    "    p <- ggplot(historic_data, aes(x = .data[[var]])) +\n",
    "      geom_histogram(bins = 10, fill = \"#2E86AB\", color = \"#023E73\", alpha = 0.85) +\n",
    "      geom_vline(aes(xintercept = mean(.data[[var]], na.rm = TRUE)),\n",
    "                 color = \"#E63946\", linetype = \"dashed\", size = 1.2) +\n",
    "      geom_vline(aes(xintercept = median(.data[[var]], na.rm = TRUE)),\n",
    "                 color = \"#06FFA5\", linetype = \"dashed\", size = 1.2) +\n",
    "      theme_minimal() +\n",
    "      theme(\n",
    "        plot.title = element_text(size = 13, face = \"bold\", hjust = 0.5),\n",
    "        plot.subtitle = element_text(size = 9, hjust = 0.5, color = \"gray30\"),\n",
    "        axis.title = element_text(size = 10, face = \"bold\"),\n",
    "        axis.text.x = element_text(size = 9),\n",
    "        panel.grid.minor = element_blank()\n",
    "      ) +\n",
    "      labs(\n",
    "        title = paste(\"Distribution:\", var),\n",
    "        subtitle = sprintf(\"Mean=%.1f | Median=%.1f | SD=%.1f (Integer)\",\n",
    "                          mean(historic_data[[var]], na.rm = TRUE),\n",
    "                          median(historic_data[[var]], na.rm = TRUE),\n",
    "                          sd(historic_data[[var]], na.rm = TRUE)),\n",
    "        x = var,\n",
    "        y = \"Frequency\"\n",
    "      )\n",
    "    \n",
    "    print(p)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170917ea",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# ORDINAL VARIABLES: HISTOGRAMS\n",
    "# =====================================================\n",
    "\n",
    "cat(\"\\n=== Ordinal Variable Distributions (Histograms) ===\\n\")\n",
    "\n",
    "if(length(ordinal_vars) > 0) {\n",
    "  \n",
    "  for(var in ordinal_vars[1:min(8, length(ordinal_vars))]) {\n",
    "    \n",
    "    freq_data <- as.data.frame(table(historic_data[[var]])) %>%\n",
    "      arrange(Var1)\n",
    "    \n",
    "    colnames(freq_data) <- c(\"Category\", \"Count\")\n",
    "    \n",
    "    # Calculate numeric stats for subtitle\n",
    "    numeric_vals <- as.numeric(as.factor(historic_data[[var]]))\n",
    "    mean_val <- mean(numeric_vals, na.rm = TRUE)\n",
    "    median_val <- median(numeric_vals, na.rm = TRUE)\n",
    "    sd_val <- sd(numeric_vals, na.rm = TRUE)\n",
    "    \n",
    "    p <- ggplot(freq_data, aes(x = Category, y = Count)) +\n",
    "      geom_bar(stat = \"identity\", fill = \"#6A4C93\", color = \"#1A1423\", alpha = 0.85) +\n",
    "      geom_text(aes(label = Count), vjust = -0.5, size = 3.5, fontface = \"bold\") +\n",
    "      theme_minimal() +\n",
    "      theme(\n",
    "        plot.title = element_text(size = 13, face = \"bold\", hjust = 0.5),\n",
    "        plot.subtitle = element_text(size = 9, hjust = 0.5, color = \"gray30\"),\n",
    "        axis.title = element_text(size = 10, face = \"bold\"),\n",
    "        axis.text.x = element_text(angle = 45, hjust = 1, size = 9)\n",
    "      ) +\n",
    "      labs(\n",
    "        title = paste(\"Distribution:\", var),\n",
    "        subtitle = sprintf(\"Mean=%.2f | Median=%.2f | SD=%.2f (Ordinal)\", \n",
    "                          mean_val, median_val, sd_val),\n",
    "        x = \"Category\",\n",
    "        y = \"Frequency\"\n",
    "      )\n",
    "    \n",
    "    print(p)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ccbf5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# CONTINUOUS VARIABLES: BOX & WHISKER PLOTS\n",
    "# =====================================================\n",
    "\n",
    "cat(\"\\n=== Continuous Variable Distributions (Box & Whisker Plots) ===\\n\")\n",
    "\n",
    "if(length(continuous_vars) > 0) {\n",
    "  \n",
    "  for(var in continuous_vars[1:min(10, length(continuous_vars))]) {\n",
    "    \n",
    "    # Calculate outlier boundaries\n",
    "    Q1 <- quantile(historic_data[[var]], 0.25, na.rm = TRUE)\n",
    "    Q3 <- quantile(historic_data[[var]], 0.75, na.rm = TRUE)\n",
    "    IQR_val <- Q3 - Q1\n",
    "    lower_bound <- Q1 - 1.5 * IQR_val\n",
    "    upper_bound <- Q3 + 1.5 * IQR_val\n",
    "    \n",
    "    # Identify outliers\n",
    "    outliers <- historic_data %>%\n",
    "      filter(!is.na(.data[[var]])) %>%\n",
    "      filter(.data[[var]] < lower_bound | .data[[var]] > upper_bound) %>%\n",
    "      select(!!sym(var))\n",
    "    \n",
    "    n_outliers <- nrow(outliers)\n",
    "    \n",
    "    p <- ggplot(historic_data, aes(y = .data[[var]])) +\n",
    "      geom_boxplot(aes(x = \"\"), \n",
    "                   fill = \"#4ECDC4\", \n",
    "                   color = \"#023E73\", \n",
    "                   alpha = 0.7,\n",
    "                   outlier.colour = \"#E63946\",\n",
    "                   outlier.shape = 16,\n",
    "                   outlier.size = 2,\n",
    "                   outlier.alpha = 0.6,\n",
    "                   width = 0.5) +\n",
    "      stat_boxplot(aes(x = \"\"), geom = \"errorbar\", width = 0.3, color = \"#023E73\") +\n",
    "      theme_minimal() +\n",
    "      theme(\n",
    "        plot.title = element_text(size = 13, face = \"bold\", hjust = 0.5),\n",
    "        plot.subtitle = element_text(size = 9, hjust = 0.5, color = \"gray30\"),\n",
    "        axis.title = element_text(size = 10, face = \"bold\"),\n",
    "        axis.text = element_text(size = 9),\n",
    "        axis.title.x = element_blank(),\n",
    "        axis.text.x = element_blank(),\n",
    "        panel.grid.major.x = element_blank()\n",
    "      ) +\n",
    "      labs(\n",
    "        title = paste(\"Distribution:\", var),\n",
    "        subtitle = sprintf(\"Median=%.2f | IQR=%.2f | Outliers=%d (Continuous)\",\n",
    "                          median(historic_data[[var]], na.rm = TRUE),\n",
    "                          IQR_val, n_outliers),\n",
    "        y = var\n",
    "      ) +\n",
    "      scale_y_continuous(labels = scales::comma)\n",
    "    \n",
    "    print(p)\n",
    "  }\n",
    "  \n",
    "  # Multi-panel box plot overview\n",
    "  cat(\"\\n--- Multi-Panel Box Plot Overview ---\\n\")\n",
    "  \n",
    "  continuous_sample_vars <- continuous_vars[1:min(9, length(continuous_vars))]\n",
    "  \n",
    "  if(length(continuous_sample_vars) >= 3) {\n",
    "    \n",
    "    plot_data_long <- historic_data %>%\n",
    "      select(all_of(continuous_sample_vars)) %>%\n",
    "      pivot_longer(everything(), names_to = \"Variable\", values_to = \"Value\")\n",
    "    \n",
    "    p_multi <- ggplot(plot_data_long, aes(x = \"\", y = Value)) +\n",
    "      geom_boxplot(fill = \"#38B000\", \n",
    "                   color = \"#1A5E00\", \n",
    "                   alpha = 0.7,\n",
    "                   outlier.colour = \"#E63946\",\n",
    "                   outlier.shape = 16,\n",
    "                   outlier.size = 1,\n",
    "                   outlier.alpha = 0.5) +\n",
    "      facet_wrap(~Variable, scales = \"free_y\", ncol = 3) +\n",
    "      theme_minimal() +\n",
    "      theme(\n",
    "        plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n",
    "        strip.text = element_text(size = 9, face = \"bold\"),\n",
    "        axis.text.y = element_text(size = 7),\n",
    "        axis.text.x = element_blank(),\n",
    "        axis.title = element_text(size = 9),\n",
    "        axis.title.x = element_blank(),\n",
    "        panel.grid.major.x = element_blank()\n",
    "      ) +\n",
    "      labs(\n",
    "        title = \"Continuous Variables - Box & Whisker Plot Overview\",\n",
    "        y = \"Value\"\n",
    "      ) +\n",
    "      scale_y_continuous(labels = scales::comma)\n",
    "    \n",
    "    print(p_multi)\n",
    "  }\n",
    "  \n",
    "  # Horizontal box plots for comparison\n",
    "  cat(\"\\n--- Horizontal Comparison Box Plots ---\\n\")\n",
    "  \n",
    "  if(length(continuous_sample_vars) >= 3) {\n",
    "    \n",
    "    # Normalize data for better comparison\n",
    "    plot_data_long_scaled <- historic_data %>%\n",
    "      select(all_of(continuous_sample_vars)) %>%\n",
    "      mutate(across(everything(), ~scale(.x)[,1])) %>%\n",
    "      pivot_longer(everything(), names_to = \"Variable\", values_to = \"Scaled_Value\")\n",
    "    \n",
    "    p_horizontal <- ggplot(plot_data_long_scaled, \n",
    "                           aes(x = reorder(Variable, Scaled_Value, FUN = median), \n",
    "                               y = Scaled_Value)) +\n",
    "      geom_boxplot(fill = \"#FF6B6B\", \n",
    "                   color = \"#C92A2A\", \n",
    "                   alpha = 0.7,\n",
    "                   outlier.colour = \"#E63946\",\n",
    "                   outlier.shape = 16,\n",
    "                   outlier.size = 1.5,\n",
    "                   outlier.alpha = 0.6) +\n",
    "      coord_flip() +\n",
    "      theme_minimal() +\n",
    "      theme(\n",
    "        plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n",
    "        plot.subtitle = element_text(size = 9, hjust = 0.5, color = \"gray30\"),\n",
    "        axis.title = element_text(size = 10, face = \"bold\"),\n",
    "        axis.text = element_text(size = 9)\n",
    "      ) +\n",
    "      labs(\n",
    "        title = \"Continuous Variables - Standardized Comparison\",\n",
    "        subtitle = \"Scaled to mean=0, SD=1 for comparison\",\n",
    "        x = \"Variable\",\n",
    "        y = \"Standardized Value\"\n",
    "      ) +\n",
    "      geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray40\", size = 0.8)\n",
    "    \n",
    "    print(p_horizontal)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21514255",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# NOMINAL VARIABLES: PIE CHARTS\n",
    "# =====================================================\n",
    "\n",
    "cat(\"\\n=== Nominal Variable Distributions (Pie Charts) ===\\n\")\n",
    "\n",
    "if(length(nominal_vars) > 0) {\n",
    "  \n",
    "  for(var in nominal_vars[1:min(8, length(nominal_vars))]) {\n",
    "    \n",
    "    # Get frequency data (top 8 categories + \"Other\")\n",
    "    freq_table <- table(historic_data[[var]], useNA = \"no\")\n",
    "    freq_df <- as.data.frame(freq_table) %>%\n",
    "      arrange(desc(Freq))\n",
    "    \n",
    "    colnames(freq_df) <- c(\"Category\", \"Count\")\n",
    "    \n",
    "    # Keep top 7, group rest as \"Other\"\n",
    "    if(nrow(freq_df) > 7) {\n",
    "      top_cats <- freq_df[1:7, ]\n",
    "      other_count <- sum(freq_df$Count[8:nrow(freq_df)])\n",
    "      freq_df <- rbind(top_cats, data.frame(Category = \"Other\", Count = other_count))\n",
    "    }\n",
    "    \n",
    "    freq_df <- freq_df %>%\n",
    "      mutate(\n",
    "        Percentage = round(Count / sum(Count) * 100, 1),\n",
    "        Label = ifelse(Percentage >= 3, paste0(Percentage, \"%\"), \"\")\n",
    "      )\n",
    "    \n",
    "    p_pie <- ggplot(freq_df, aes(x = \"\", y = Count, fill = Category)) +\n",
    "      geom_bar(stat = \"identity\", width = 1, color = \"white\", size = 1.5) +\n",
    "      coord_polar(\"y\", start = 0) +\n",
    "      geom_text(aes(label = Label), \n",
    "                position = position_stack(vjust = 0.5),\n",
    "                size = 3.5, fontface = \"bold\", color = \"black\") +\n",
    "      theme_void() +\n",
    "      theme(\n",
    "        plot.title = element_text(size = 13, face = \"bold\", hjust = 0.5, margin = margin(b = 10)),\n",
    "        plot.subtitle = element_text(size = 9, hjust = 0.5, color = \"gray40\", margin = margin(b = 15)),\n",
    "        legend.position = \"right\",\n",
    "        legend.title = element_text(size = 10, face = \"bold\"),\n",
    "        legend.text = element_text(size = 8)\n",
    "      ) +\n",
    "      labs(\n",
    "        title = paste(\"Distribution:\", var),\n",
    "        subtitle = paste(\"(Nominal -\", length(freq_table), \"unique values)\"),\n",
    "        fill = \"Category\"\n",
    "      ) +\n",
    "      scale_fill_brewer(palette = \"Set3\")\n",
    "    \n",
    "    print(p_pie)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d58c6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# BOOLEAN VARIABLES: BAR CHARTS\n",
    "# =====================================================\n",
    "\n",
    "cat(\"\\n=== Boolean Variable Distributions (Bar Charts) ===\\n\")\n",
    "\n",
    "if(length(boolean_vars) > 0) {\n",
    "  \n",
    "  for(var in boolean_vars) {\n",
    "    \n",
    "    if(var %in% names(historic_data)) {\n",
    "      \n",
    "      freq_data <- data.frame(\n",
    "        Value = c(\"TRUE\", \"FALSE\"),\n",
    "        Count = c(\n",
    "          sum(historic_data[[var]], na.rm = TRUE),\n",
    "          sum(!historic_data[[var]], na.rm = TRUE)\n",
    "        )\n",
    "      ) %>%\n",
    "        mutate(\n",
    "          Percentage = round(Count / sum(Count) * 100, 1),\n",
    "          Label = paste0(Count, \"\\n(\", Percentage, \"%)\")\n",
    "        )\n",
    "      \n",
    "      p_bar <- ggplot(freq_data, aes(x = Value, y = Count, fill = Value)) +\n",
    "        geom_bar(stat = \"identity\", color = \"black\", alpha = 0.85, width = 0.6) +\n",
    "        geom_text(aes(label = Label), vjust = -0.5, size = 4, fontface = \"bold\") +\n",
    "        theme_minimal() +\n",
    "        theme(\n",
    "          plot.title = element_text(size = 13, face = \"bold\", hjust = 0.5),\n",
    "          plot.subtitle = element_text(size = 9, hjust = 0.5, color = \"gray30\"),\n",
    "          axis.title = element_text(size = 10, face = \"bold\"),\n",
    "          axis.text = element_text(size = 10),\n",
    "          legend.position = \"none\",\n",
    "          panel.grid.major.x = element_blank()\n",
    "        ) +\n",
    "        labs(\n",
    "          title = paste(\"Distribution:\", var),\n",
    "          subtitle = \"(Boolean Variable)\",\n",
    "          x = \"Value\",\n",
    "          y = \"Count\"\n",
    "        ) +\n",
    "        scale_fill_manual(values = c(\"TRUE\" = \"#4CAF50\", \"FALSE\" = \"#F44336\")) +\n",
    "        scale_y_continuous(expand = expansion(mult = c(0, 0.15)))\n",
    "      \n",
    "      print(p_bar)\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402067d8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# CORRELATION ANALYSIS\n",
    "# =====================================================\n",
    "\n",
    "cat(\"\\n=== Correlation Analysis ===\\n\")\n",
    "\n",
    "# Combine integer, continuous, and ordinal (as numeric) for correlation\n",
    "numeric_for_corr <- c(integer_vars, continuous_vars)\n",
    "numeric_for_corr <- intersect(numeric_for_corr, names(historic_data))\n",
    "\n",
    "# Add ordinal as numeric\n",
    "if(length(ordinal_vars) > 0) {\n",
    "  ordinal_in_data <- intersect(ordinal_vars, names(historic_data))\n",
    "  numeric_for_corr <- c(numeric_for_corr, ordinal_in_data)\n",
    "}\n",
    "\n",
    "if(length(numeric_for_corr) >= 2) {\n",
    "  \n",
    "  # Prepare data - convert ordinal to numeric\n",
    "  cor_data <- historic_data %>%\n",
    "    select(all_of(numeric_for_corr))\n",
    "  \n",
    "  # Convert ordinal columns to numeric\n",
    "  for(col in ordinal_in_data) {\n",
    "    if(col %in% names(cor_data)) {\n",
    "      cor_data[[col]] <- as.numeric(as.factor(cor_data[[col]]))\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Keep only numeric columns\n",
    "  cor_data <- cor_data %>%\n",
    "    select(where(is.numeric))\n",
    "  \n",
    "  # Remove zero-variance columns\n",
    "  cor_data <- cor_data %>%\n",
    "    select(where(~var(.x, na.rm = TRUE) > 0))\n",
    "  \n",
    "  # Calculate correlation matrix\n",
    "  cor_matrix <- cor(cor_data, use = \"pairwise.complete.obs\")\n",
    "  \n",
    "  # Full correlation heatmap\n",
    "  cat(\"\\n--- Creating Correlation Heatmap ---\\n\")\n",
    "  \n",
    "  corrplot(cor_matrix, \n",
    "           method = \"color\",\n",
    "           type = \"upper\",\n",
    "           order = \"hclust\",\n",
    "           tl.col = \"black\",\n",
    "           tl.srt = 45,\n",
    "           tl.cex = 0.7,\n",
    "           cl.cex = 0.8,\n",
    "           col = colorRampPalette(c(\"#D32F2F\", \"#FFFFFF\", \"#1976D2\"))(200),\n",
    "           title = \"Correlation Matrix - Numeric Variables (incl. Ordinal)\",\n",
    "           mar = c(0, 0, 2, 0))\n",
    "  \n",
    "  # Sale price correlations\n",
    "  if(\"sale_price\" %in% colnames(cor_matrix)) {\n",
    "    cat(\"\\n--- Top Correlations with Sale Price ---\\n\")\n",
    "    \n",
    "    price_cors <- cor_matrix[\"sale_price\", ]\n",
    "    price_cors <- price_cors[order(abs(price_cors), decreasing = TRUE)]\n",
    "    price_cors <- price_cors[names(price_cors) != \"sale_price\"]\n",
    "    \n",
    "    top_15 <- head(price_cors, 15)\n",
    "    for(i in seq_along(top_15)) {\n",
    "      cat(sprintf(\"  %s: %.3f\\n\", names(top_15)[i], top_15[i]))\n",
    "    }\n",
    "    \n",
    "    # Bar chart of correlations\n",
    "    price_cor_df <- data.frame(\n",
    "      Variable = names(top_15),\n",
    "      Correlation = as.numeric(top_15)\n",
    "    )\n",
    "    \n",
    "    p_cor <- ggplot(price_cor_df, aes(x = reorder(Variable, abs(Correlation)), \n",
    "                                       y = Correlation, fill = Correlation > 0)) +\n",
    "      geom_bar(stat = \"identity\", color = \"black\", alpha = 0.85) +\n",
    "      geom_text(aes(label = sprintf(\"%.2f\", Correlation)),\n",
    "                hjust = ifelse(price_cor_df$Correlation > 0, -0.2, 1.2),\n",
    "                size = 3.5, fontface = \"bold\") +\n",
    "      coord_flip() +\n",
    "      theme_minimal() +\n",
    "      theme(\n",
    "        plot.title = element_text(size = 14, face = \"bold\", hjust = 0.5),\n",
    "        axis.title = element_text(size = 11, face = \"bold\"),\n",
    "        legend.position = \"none\"\n",
    "      ) +\n",
    "      labs(\n",
    "        title = \"Top 15 Correlations with Sale Price\",\n",
    "        x = \"Variable\",\n",
    "        y = \"Correlation Coefficient\"\n",
    "      ) +\n",
    "      scale_fill_manual(values = c(\"TRUE\" = \"#2E7D32\", \"FALSE\" = \"#C62828\")) +\n",
    "      geom_hline(yintercept = 0, linetype = \"solid\", color = \"black\", size = 0.8)\n",
    "    \n",
    "    print(p_cor)\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"\\n=== EDA Complete ===\\n\")\n",
    "cat(\"\\nVisualization Summary:\")\n",
    "cat(\"\\n  - Integer: Histograms\")\n",
    "cat(\"\\n  - Continuous: Box & Whisker Plots (red outliers)\")\n",
    "cat(\"\\n  - Ordinal: Numeric stats + Histograms\")\n",
    "cat(\"\\n  - Nominal: Pie Charts\")\n",
    "cat(\"\\n  - Boolean: Bar Charts\")\n",
    "cat(\"\\n  - Correlation: Heatmap (Integer + Continuous + Ordinal)\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff99f544",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
